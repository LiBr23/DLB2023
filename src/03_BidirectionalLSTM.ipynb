{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPws/ZtPApq7HKi8prPXYjE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## ドライブのマウント"],"metadata":{"id":"weImdw8_hbdX"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WdFP5dZIduNK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690845224257,"user_tz":420,"elapsed":60799,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"9ded2560-df7d-43cc-f9b7-1744c37984de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Colab Notebooks/DLBasics2023_colab/submit/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3q2P6B2kOS-W","executionInfo":{"status":"ok","timestamp":1690845225812,"user_tz":420,"elapsed":1557,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"208e326e-4a92-4174-8498-1e0cc0bf234b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/DLBasics2023_colab/submit\n"]}]},{"cell_type":"markdown","source":["## ライブラリのインポート"],"metadata":{"id":"Tw27K5y9hjQm"}},{"cell_type":"code","source":["!pip install portalocker\n","\n","import random\n","import numpy as np\n","from collections import Counter\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torchtext.vocab import vocab\n","from torchtext.data.utils import get_tokenizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n","import matplotlib.pyplot as plt\n","\n","seed = 1234\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubPeSa8IhiIa","executionInfo":{"status":"ok","timestamp":1690845234998,"user_tz":420,"elapsed":9191,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"c5edef44-b743-4ee2-93e0-5fd5aee1cf02"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-2.7.0\n"]}]},{"cell_type":"markdown","source":["## データの読み込み"],"metadata":{"id":"zkM2USkJxG0r"}},{"cell_type":"markdown","source":["csvからPytorchのDatasetを作る方法\n","参考\n","- https://dreamer-uma.com/pytorch-dataset/\n","- https://discuss.pytorch.org/t/loading-a-csv-with-a-column-of-strings-and-a-column-of-integers/151080/4"],"metadata":{"id":"d3iL4gwNxJUf"}},{"cell_type":"markdown","source":["csv場所の定義"],"metadata":{"id":"CfADKkhg17qB"}},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","path_to_csv_file = './data/labels/labels_sensitivity_evaluation.csv'\n"],"metadata":{"id":"vsr7JuydxS3y","executionInfo":{"status":"ok","timestamp":1690845235327,"user_tz":420,"elapsed":338,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["PyTorchのDataset形式でcsvデータを読み込み(headerは自動で認識)"],"metadata":{"id":"SzkknxD11-I7"}},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        self.data = df\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        label = row[1]\n","        comment = row[3]\n","        sample = (label, comment)\n","        return sample\n","\n","# データフレーム全体を読み込む\n","labels_dataframe = pd.read_csv(path_to_csv_file)\n","\n","# 嗜好が3のものは除外する\n","labels_dataframe = labels_dataframe[labels_dataframe.iloc[:, 1]!=3]\n","\n","# 2列目の値が1,2のものを0に変換\n","labels_dataframe.iloc[:, 1].replace([1, 2], 0, inplace=True)\n","\n","# 2列目の値が4,5のものを1に変換\n","labels_dataframe.iloc[:, 1].replace([4, 5], 1, inplace=True)\n","\n","# trainとtest用にデータを8:2に分割\n","trainval_df, test_df = train_test_split(labels_dataframe, test_size=0.2, random_state=42, stratify=labels_dataframe['label'])\n","\n","# 分割したデータフレームをそれぞれのインスタンスに渡す。\n","trainval_data = CustomDataset(trainval_df)\n","test_data = CustomDataset(test_df)\n"],"metadata":{"id":"iY2MbJlL1HdN","executionInfo":{"status":"ok","timestamp":1690845236390,"user_tz":420,"elapsed":1065,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["ちゃんと読み込めているか確認"],"metadata":{"id":"gM_PM9jR2IVT"}},{"cell_type":"code","source":["# for foo in trainval_data:\n","#     print(foo)"],"metadata":{"id":"MOuaMonS8XnL","executionInfo":{"status":"ok","timestamp":1690845236390,"user_tz":420,"elapsed":14,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# for foo in test_data:\n","#     print(foo)"],"metadata":{"id":"SafZFsB40Fwy","executionInfo":{"status":"ok","timestamp":1690845236390,"user_tz":420,"elapsed":13,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## trainとvalidにデータを分割"],"metadata":{"id":"bt29UGlX4VkM"}},{"cell_type":"markdown","source":["参考\n","- https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets"],"metadata":{"id":"yVTkzjvo4qyC"}},{"cell_type":"code","source":["train_size = int(0.8 * len(trainval_data))\n","valid_size = len(trainval_data) - train_size\n","train_dataset, vaild_dataset = torch.utils.data.random_split(trainval_data, [train_size, valid_size])"],"metadata":{"id":"SJkAY4Kh4a0D","executionInfo":{"status":"ok","timestamp":1690845236390,"user_tz":420,"elapsed":12,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## 語彙リスト作成"],"metadata":{"id":"0PbCfX8T46T5"}},{"cell_type":"markdown","source":["単語数をカウント"],"metadata":{"id":"5gD7I8L2926R"}},{"cell_type":"code","source":["# 単語をスペースで区切り，!\"#$%&といった記号を除去する，すべて小文字化する，などの処理\n","# https://pytorch.org/text/stable/data_utils.html\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","counter = Counter()\n","\n","for label, comment in train_dataset:\n","    counter.update(tokenizer(comment))\n","\n","vocabulary = vocab(\n","    counter,\n","    min_freq=5,\n","    specials=('<unk>', '<PAD>', '<BOS>', '<EOS>')\n",")\n","# <unk>をデフォルトに設定することにより，min_freq回以上出てこない単語は<unk>になる\n","vocabulary.set_default_index(vocabulary['<unk>'])\n","\n","word_num = len(vocabulary)\n","\n","print(f\"単語種数: {word_num}\")\n","print(*vocabulary.get_itos()[:100], sep=', ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-F7s8aJ45K1","executionInfo":{"status":"ok","timestamp":1690845236390,"user_tz":420,"elapsed":12,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"52247117-a09d-44c4-d2da-b98b120dad67"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["単語種数: 84\n","<unk>, <PAD>, <BOS>, <EOS>, the, expression, is, scary, ., flash, strong, ,, eyes, are, a, bit, and, i, don, ', t, like, pose, gaze, at, it, difficult, to, see, cute, that, eye, in, for, an, out, fur, also, well-resolved, face, hard, identify, light, s, good, has, seems, be, something, on, there, not, too, nice, but, cat, from, posture, moment, of, looks, because, blurred, cool, black, which, focus, background, color, feel, well, text, unnecessary, pattern, beautiful, resolved, feeling, natural, angle, white, photo, soft, looking, with\n"]}]},{"cell_type":"markdown","source":["text_transform()をcollate_batch()から呼び，単語のリストを辞書内インデックスのリストに変換"],"metadata":{"id":"y-VeRO2Y9XoE"}},{"cell_type":"code","source":["def text_transform(_text, max_length=256):\n","    # <BOS>と<EOS>の分 -2\n","    text = [vocabulary[token] for token in tokenizer(_text)][:max_length - 2]\n","    text = [vocabulary['<BOS>']] + text + [vocabulary['<EOS>']]\n","\n","    return text, len(text)\n","\n","def collate_batch(batch):\n","    label_list, text_list, len_seq_list = [], [], []\n","\n","    for _label, _text in batch:\n","      label_list.append(_label)\n","\n","      processed_text, len_seq = text_transform(_text)\n","      text_list.append(torch.tensor(processed_text))\n","      len_seq_list.append(len_seq)\n","    return torch.tensor(label_list), pad_sequence(text_list, padding_value=1).T, torch.tensor(len_seq_list)"],"metadata":{"id":"UfzpMKN65BQd","executionInfo":{"status":"ok","timestamp":1690845236391,"user_tz":420,"elapsed":6,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["上で定義したcollate_batch()をDataLoaderに渡すことで，バッチに対してその処理を適用"],"metadata":{"id":"fl_49VY49imd"}},{"cell_type":"code","source":["batch_size = 32\n","\n","train_dataloader = DataLoader(\n","   list(train_dataset),\n","   batch_size=batch_size,\n","   shuffle=True,\n","   collate_fn=collate_batch\n",")\n","valid_dataloader = DataLoader(\n","   list(vaild_dataset),\n","   batch_size=batch_size,\n","   shuffle=False,\n","   collate_fn=collate_batch\n",")\n","\n","test_dataloader = DataLoader(\n","   list(test_data),\n","   batch_size=batch_size,\n","   shuffle=False,\n","   collate_fn=collate_batch\n",")\n"],"metadata":{"id":"g941jqht9jNd","executionInfo":{"status":"ok","timestamp":1690845236391,"user_tz":420,"elapsed":5,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## 双方向LSTM実装"],"metadata":{"id":"9jyn9LVm-ode"}},{"cell_type":"code","source":["def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))\n","\n","\n","class Embedding(nn.Module):\n","    # WRITE ME\n","    def __init__(self, emb_dim, vocab_size):\n","        super().__init__()\n","        self.embedding_matrix = nn.Parameter(torch.rand((vocab_size, emb_dim),\n","                                                        dtype=torch.float))\n","\n","    def forward(self, x):\n","        return F.embedding(x, self.embedding_matrix)\n","\n","\n","\n","class RNN(nn.Module):\n","    def __init__(self, in_dim, hid_dim):\n","        super().__init__()\n","        self.hid_dim = hid_dim\n","\n","        # 一様分布の時の処理\n","        glorot = 6 / (in_dim + hid_dim*2)\n","        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n","                        low=-np.sqrt(glorot),\n","                        high=np.sqrt(glorot),\n","                        size=(in_dim + hid_dim, hid_dim)\n","                    ).astype('float32')))\n","        self.b = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n","\n","    def function(self, h, x):\n","        return torch.tanh(torch.matmul(torch.cat([h, x], dim=1), self.W) + self.b)\n","\n","    def forward(self, x, len_seq_max=0, init_state=None):\n","        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n","        state = init_state\n","\n","        if init_state is None:  # 初期値を設定しない場合は0で初期化する\n","            state = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n","\n","        size = list(state.unsqueeze(0).size())\n","        size[0] = 0\n","        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n","\n","        if len_seq_max == 0:\n","            len_seq_max = x.size(0)\n","        for i in range(len_seq_max):\n","            state = self.function(state, x[i])\n","            output = torch.cat([output, state.unsqueeze(0)])  # 出力系列の追加\n","        return output\n","\n","\n","class SequenceTaggingNet(nn.Module):\n","    def __init__(self, word_num, emb_dim, hid_dim, dropout_ratio):\n","        super().__init__()\n","        self.emb = Embedding(emb_dim, word_num)\n","        self.rnn1 = RNN(emb_dim, hid_dim)\n","        self.rnn2 = RNN(emb_dim, hid_dim)  # 層の追加\n","        self.rnn3= RNN(emb_dim, hid_dim)  # 層の追加\n","        self.rnn4 = RNN(emb_dim, hid_dim)  # 層の追加\n","        self.rnn5 = RNN(emb_dim, hid_dim)  # 層の追加\n","        self.linear = nn.Linear(hid_dim, 1)\n","\n","        self.dropout = nn.Dropout(dropout_ratio)  # Dropoutの定義\n","\n","\n","\n","    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n","        h = self.emb(x)\n","\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","        h = self.rnn1(h, len_seq_max, init_state)\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","        h = self.rnn2(h, len_seq_max)               # 層の追加\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","        h = self.rnn3(h, len_seq_max)               # 層の追加\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","        h = self.rnn4(h, len_seq_max)               # 層の追加\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","        h = self.rnn5(h, len_seq_max)               # 層の追加\n","        h = self.dropout(h)                          # Dropoutの適用\n","\n","\n","        if len_seq is not None:\n","            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n","            h = h[len_seq - 1, list(range(len(x))), :]\n","        else:\n","            h = h[-1]\n","\n","        y = self.linear(h)\n","\n","\n","\n","        return y\n","\n","\n","# 比較するためにこちらも実装\n","class SequenceTaggingNet2(nn.Module):\n","    def __init__(self, word_num, emb_dim, hid_dim, dropout_ratio):\n","        super().__init__()\n","        self.emb = nn.Embedding(word_num, emb_dim)  # nn.Embeddingの使用\n","        self.rnn = nn.RNN(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=False)  # nn.RNNの使用\n","        self.linear = nn.Linear(hid_dim, 1)\n","\n","    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n","        h = self.emb(x)\n","\n","\n","        if len_seq_max > 0:\n","            h, _ = self.rnn(h[:, 0:len_seq_max, :], init_state)\n","        else:\n","            h, _ = self.rnn(h, init_state)\n","        h = h.transpose(0, 1)\n","        if len_seq is None:\n","            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n","            h = h[len_seq - 1, list(range(len(x))), :]\n","        else:\n","            h = h[-1]\n","\n","\n","\n","        y = self.linear(h)\n","\n","        return y\n","\n","\n","\n"],"metadata":{"id":"-cG0yJPQ-Z0t","executionInfo":{"status":"ok","timestamp":1690845236391,"user_tz":420,"elapsed":5,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# cosine scheduler\n","class CosineScheduler:\n","    def __init__(self, epochs, lr, warmup_length=5):\n","        \"\"\"\n","        Arguments\n","        ---------\n","        epochs : int\n","            学習のエポック数．\n","        lr : float\n","            学習率．\n","        warmup_length : int\n","            warmupを適用するエポック数．\n","        \"\"\"\n","        self.epochs = epochs\n","        self.lr = lr\n","        self.warmup = warmup_length\n","\n","    def __call__(self, epoch):\n","        \"\"\"\n","        Arguments\n","        ---------\n","        epoch : int\n","            現在のエポック数．\n","        \"\"\"\n","        progress = (epoch - self.warmup) / (self.epochs - self.warmup)\n","        progress = np.clip(progress, 0.0, 1.0)\n","        lr = self.lr * 0.5 * (1. + np.cos(np.pi * progress))\n","\n","        if self.warmup:\n","            lr = lr * min(1., (epoch+1) / self.warmup)\n","\n","        return lr\n","\n","def set_lr(lr, optimizer):\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr"],"metadata":{"id":"d2apfQdkD3mI","executionInfo":{"status":"ok","timestamp":1690845236391,"user_tz":420,"elapsed":5,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# NOTE: dataloaderはグローバルスコープ\n","def train(\n","    net,\n","    optimizer,\n","    n_epochs,\n","):\n","    for epoch in range(n_epochs):\n","\n","        # スケジューラで学習率を更新する\n","        new_lr = scheduler(epoch)\n","        set_lr(new_lr, optimizer)\n","\n","        losses_train = []\n","        losses_valid = []\n","\n","        net.train()\n","        n_train = 0\n","        acc_train = 0\n","        for label, line, len_seq in train_dataloader:\n","            net.zero_grad()  # 勾配の初期化\n","\n","            t = label.to(device) # テンソルをGPUに移動\n","            x = line.to(device) # ( batch, time )\n","            len_seq.to(device)\n","\n","            h = net(x, torch.max(len_seq), len_seq)\n","            y = torch.sigmoid(h).squeeze()\n","\n","            loss = -torch.mean(t * torch_log(y) + (1 - t) * torch_log(1 - y))\n","\n","            loss.backward()  # 誤差の逆伝播\n","\n","            optimizer.step()  # パラメータの更新\n","\n","            losses_train.append(loss.tolist())\n","\n","            n_train += t.size()[0]\n","\n","        # Valid\n","        t_valid = []\n","        y_pred = []\n","        net.eval()\n","        for label, line, len_seq in valid_dataloader:\n","\n","            t = label.to(device) # テンソルをGPUに移動\n","            x = line.to(device)\n","            len_seq.to(device)\n","\n","            h = net(x, torch.max(len_seq), len_seq)\n","            y = torch.sigmoid(h).squeeze()\n","\n","            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n","\n","            pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n","\n","            t_valid.extend(t.tolist())\n","            y_pred.extend(pred.tolist())\n","\n","            losses_valid.append(loss.tolist())\n","\n","        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}, Learning Rate: {}'.format(\n","            epoch,\n","            np.mean(losses_train),\n","            np.mean(losses_valid),\n","            f1_score(t_valid, y_pred, average='macro'),\n","            new_lr\n","        ))\n","\n"],"metadata":{"id":"andRXAdY-8BE","executionInfo":{"status":"ok","timestamp":1690845236391,"user_tz":420,"elapsed":4,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["emb_dim = 400\n","hid_dim = 100\n","n_epochs = 1000\n","warmup_length = round(n_epochs * 0.1, 0)\n","\n","device = 'cuda'\n","weight_decay = 0 # 過学習抑制のためのL2 penalty\n","lr = 0.1\n","dropout_ratio = 0\n","\n","net = SequenceTaggingNet2(word_num, emb_dim, hid_dim, dropout_ratio)\n","net.to(device)\n","\n","# 学習率の更新定義\n","scheduler = CosineScheduler(epochs=n_epochs, lr=lr, warmup_length=warmup_length)\n","\n","optimizer = optim.NAdam(net.parameters(), weight_decay = weight_decay, lr = lr)\n","\n"],"metadata":{"id":"7wERzmAc-8os","executionInfo":{"status":"ok","timestamp":1690845236743,"user_tz":420,"elapsed":356,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train(net, optimizer, n_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFCGkAD_-_Q5","executionInfo":{"status":"ok","timestamp":1690845265037,"user_tz":420,"elapsed":28295,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"e324cffc-46c0-48c3-f908-5317257f4061"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 0, Train Loss: 0.705, Valid Loss: 0.712, Validation F1: 0.288, Learning Rate: 0.001\n","EPOCH: 1, Train Loss: 0.691, Valid Loss: 0.692, Validation F1: 0.460, Learning Rate: 0.002\n","EPOCH: 2, Train Loss: 0.674, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.003\n","EPOCH: 3, Train Loss: 0.677, Valid Loss: 0.678, Validation F1: 0.332, Learning Rate: 0.004\n","EPOCH: 4, Train Loss: 0.665, Valid Loss: 0.667, Validation F1: 0.533, Learning Rate: 0.005000000000000001\n","EPOCH: 5, Train Loss: 0.665, Valid Loss: 0.675, Validation F1: 0.460, Learning Rate: 0.006\n","EPOCH: 6, Train Loss: 0.775, Valid Loss: 0.674, Validation F1: 0.460, Learning Rate: 0.007000000000000001\n","EPOCH: 7, Train Loss: 0.667, Valid Loss: 0.655, Validation F1: 0.460, Learning Rate: 0.008\n","EPOCH: 8, Train Loss: 0.667, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.009\n","EPOCH: 9, Train Loss: 0.700, Valid Loss: 0.903, Validation F1: 0.311, Learning Rate: 0.010000000000000002\n","EPOCH: 10, Train Loss: 0.716, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.011000000000000001\n","EPOCH: 11, Train Loss: 0.795, Valid Loss: 0.994, Validation F1: 0.460, Learning Rate: 0.012\n","EPOCH: 12, Train Loss: 0.759, Valid Loss: 0.714, Validation F1: 0.311, Learning Rate: 0.013000000000000001\n","EPOCH: 13, Train Loss: 0.711, Valid Loss: 0.728, Validation F1: 0.311, Learning Rate: 0.014000000000000002\n","EPOCH: 14, Train Loss: 0.747, Valid Loss: 0.703, Validation F1: 0.311, Learning Rate: 0.015\n","EPOCH: 15, Train Loss: 0.701, Valid Loss: 0.697, Validation F1: 0.311, Learning Rate: 0.016\n","EPOCH: 16, Train Loss: 0.715, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.017\n","EPOCH: 17, Train Loss: 0.753, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.018\n","EPOCH: 18, Train Loss: 0.735, Valid Loss: 0.682, Validation F1: 0.460, Learning Rate: 0.019000000000000003\n","EPOCH: 19, Train Loss: 0.680, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.020000000000000004\n","EPOCH: 20, Train Loss: 0.768, Valid Loss: 1.037, Validation F1: 0.460, Learning Rate: 0.021\n","EPOCH: 21, Train Loss: 0.847, Valid Loss: 0.641, Validation F1: 0.460, Learning Rate: 0.022000000000000002\n","EPOCH: 22, Train Loss: 0.690, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.023000000000000003\n","EPOCH: 23, Train Loss: 0.727, Valid Loss: 1.069, Validation F1: 0.460, Learning Rate: 0.024\n","EPOCH: 24, Train Loss: 0.779, Valid Loss: 1.079, Validation F1: 0.311, Learning Rate: 0.025\n","EPOCH: 25, Train Loss: 0.857, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.026000000000000002\n","EPOCH: 26, Train Loss: 0.822, Valid Loss: 2.169, Validation F1: 0.311, Learning Rate: 0.027000000000000003\n","EPOCH: 27, Train Loss: 0.958, Valid Loss: 1.605, Validation F1: 0.460, Learning Rate: 0.028000000000000004\n","EPOCH: 28, Train Loss: 0.943, Valid Loss: 0.748, Validation F1: 0.460, Learning Rate: 0.028999999999999998\n","EPOCH: 29, Train Loss: 0.861, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.03\n","EPOCH: 30, Train Loss: 0.746, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.031\n","EPOCH: 31, Train Loss: 0.686, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.032\n","EPOCH: 32, Train Loss: 0.904, Valid Loss: 1.277, Validation F1: 0.460, Learning Rate: 0.033\n","EPOCH: 33, Train Loss: 0.988, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.034\n","EPOCH: 34, Train Loss: 0.749, Valid Loss: 0.733, Validation F1: 0.460, Learning Rate: 0.034999999999999996\n","EPOCH: 35, Train Loss: 0.866, Valid Loss: 0.895, Validation F1: 0.460, Learning Rate: 0.036\n","EPOCH: 36, Train Loss: 1.133, Valid Loss: 1.048, Validation F1: 0.311, Learning Rate: 0.037\n","EPOCH: 37, Train Loss: 1.045, Valid Loss: 1.020, Validation F1: 0.311, Learning Rate: 0.038000000000000006\n","EPOCH: 38, Train Loss: 0.846, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.03900000000000001\n","EPOCH: 39, Train Loss: 0.749, Valid Loss: 0.640, Validation F1: 0.460, Learning Rate: 0.04000000000000001\n","EPOCH: 40, Train Loss: 0.780, Valid Loss: 0.787, Validation F1: 0.460, Learning Rate: 0.041\n","EPOCH: 41, Train Loss: 1.258, Valid Loss: 0.952, Validation F1: 0.460, Learning Rate: 0.042\n","EPOCH: 42, Train Loss: 1.083, Valid Loss: 0.797, Validation F1: 0.460, Learning Rate: 0.043000000000000003\n","EPOCH: 43, Train Loss: 1.261, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.044000000000000004\n","EPOCH: 44, Train Loss: 0.851, Valid Loss: 2.372, Validation F1: 0.460, Learning Rate: 0.045000000000000005\n","EPOCH: 45, Train Loss: 1.219, Valid Loss: 0.709, Validation F1: 0.311, Learning Rate: 0.046000000000000006\n","EPOCH: 46, Train Loss: 0.886, Valid Loss: 0.894, Validation F1: 0.460, Learning Rate: 0.047\n","EPOCH: 47, Train Loss: 0.929, Valid Loss: 0.999, Validation F1: 0.460, Learning Rate: 0.048\n","EPOCH: 48, Train Loss: 1.396, Valid Loss: 0.993, Validation F1: 0.460, Learning Rate: 0.049\n","EPOCH: 49, Train Loss: 0.987, Valid Loss: 1.052, Validation F1: 0.460, Learning Rate: 0.05\n","EPOCH: 50, Train Loss: 1.058, Valid Loss: 1.067, Validation F1: 0.460, Learning Rate: 0.051000000000000004\n","EPOCH: 51, Train Loss: 1.262, Valid Loss: 1.726, Validation F1: 0.460, Learning Rate: 0.052000000000000005\n","EPOCH: 52, Train Loss: 1.094, Valid Loss: 1.439, Validation F1: 0.311, Learning Rate: 0.053000000000000005\n","EPOCH: 53, Train Loss: 0.738, Valid Loss: 1.952, Validation F1: 0.311, Learning Rate: 0.054000000000000006\n","EPOCH: 54, Train Loss: 1.288, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.05500000000000001\n","EPOCH: 55, Train Loss: 1.252, Valid Loss: 1.047, Validation F1: 0.460, Learning Rate: 0.05600000000000001\n","EPOCH: 56, Train Loss: 0.939, Valid Loss: 1.002, Validation F1: 0.460, Learning Rate: 0.056999999999999995\n","EPOCH: 57, Train Loss: 1.606, Valid Loss: 2.756, Validation F1: 0.354, Learning Rate: 0.057999999999999996\n","EPOCH: 58, Train Loss: 1.222, Valid Loss: 0.882, Validation F1: 0.311, Learning Rate: 0.059\n","EPOCH: 59, Train Loss: 1.330, Valid Loss: 1.271, Validation F1: 0.311, Learning Rate: 0.06\n","EPOCH: 60, Train Loss: 1.152, Valid Loss: 1.872, Validation F1: 0.460, Learning Rate: 0.061\n","EPOCH: 61, Train Loss: 1.210, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.062\n","EPOCH: 62, Train Loss: 0.744, Valid Loss: 1.085, Validation F1: 0.311, Learning Rate: 0.063\n","EPOCH: 63, Train Loss: 1.340, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.064\n","EPOCH: 64, Train Loss: 0.787, Valid Loss: 1.232, Validation F1: 0.311, Learning Rate: 0.065\n","EPOCH: 65, Train Loss: 1.437, Valid Loss: 0.979, Validation F1: 0.311, Learning Rate: 0.066\n","EPOCH: 66, Train Loss: 1.309, Valid Loss: 1.723, Validation F1: 0.311, Learning Rate: 0.067\n","EPOCH: 67, Train Loss: 1.300, Valid Loss: 0.821, Validation F1: 0.311, Learning Rate: 0.068\n","EPOCH: 68, Train Loss: 1.503, Valid Loss: 0.852, Validation F1: 0.311, Learning Rate: 0.06899999999999999\n","EPOCH: 69, Train Loss: 1.703, Valid Loss: 1.951, Validation F1: 0.311, Learning Rate: 0.06999999999999999\n","EPOCH: 70, Train Loss: 1.280, Valid Loss: 0.748, Validation F1: 0.460, Learning Rate: 0.071\n","EPOCH: 71, Train Loss: 0.991, Valid Loss: 1.164, Validation F1: 0.460, Learning Rate: 0.072\n","EPOCH: 72, Train Loss: 2.275, Valid Loss: 0.704, Validation F1: 0.460, Learning Rate: 0.073\n","EPOCH: 73, Train Loss: 1.012, Valid Loss: 0.945, Validation F1: 0.311, Learning Rate: 0.074\n","EPOCH: 74, Train Loss: 1.914, Valid Loss: 4.220, Validation F1: 0.311, Learning Rate: 0.07500000000000001\n","EPOCH: 75, Train Loss: 1.637, Valid Loss: 2.807, Validation F1: 0.354, Learning Rate: 0.07600000000000001\n","EPOCH: 76, Train Loss: 1.757, Valid Loss: 2.198, Validation F1: 0.354, Learning Rate: 0.07700000000000001\n","EPOCH: 77, Train Loss: 1.545, Valid Loss: 0.686, Validation F1: 0.460, Learning Rate: 0.07800000000000001\n","EPOCH: 78, Train Loss: 1.107, Valid Loss: 0.919, Validation F1: 0.311, Learning Rate: 0.07900000000000001\n","EPOCH: 79, Train Loss: 1.585, Valid Loss: 2.431, Validation F1: 0.311, Learning Rate: 0.08000000000000002\n","EPOCH: 80, Train Loss: 1.331, Valid Loss: 0.662, Validation F1: 0.460, Learning Rate: 0.08100000000000002\n","EPOCH: 81, Train Loss: 0.748, Valid Loss: 2.676, Validation F1: 0.311, Learning Rate: 0.082\n","EPOCH: 82, Train Loss: 1.736, Valid Loss: 1.009, Validation F1: 0.311, Learning Rate: 0.083\n","EPOCH: 83, Train Loss: 1.391, Valid Loss: 0.997, Validation F1: 0.311, Learning Rate: 0.084\n","EPOCH: 84, Train Loss: 1.139, Valid Loss: 0.710, Validation F1: 0.460, Learning Rate: 0.085\n","EPOCH: 85, Train Loss: 0.924, Valid Loss: 0.848, Validation F1: 0.460, Learning Rate: 0.08600000000000001\n","EPOCH: 86, Train Loss: 1.250, Valid Loss: 0.671, Validation F1: 0.460, Learning Rate: 0.08700000000000001\n","EPOCH: 87, Train Loss: 1.319, Valid Loss: 1.047, Validation F1: 0.460, Learning Rate: 0.08800000000000001\n","EPOCH: 88, Train Loss: 1.585, Valid Loss: 2.246, Validation F1: 0.354, Learning Rate: 0.08900000000000001\n","EPOCH: 89, Train Loss: 1.718, Valid Loss: 2.628, Validation F1: 0.354, Learning Rate: 0.09000000000000001\n","EPOCH: 90, Train Loss: 1.227, Valid Loss: 0.932, Validation F1: 0.311, Learning Rate: 0.09100000000000001\n","EPOCH: 91, Train Loss: 1.531, Valid Loss: 1.985, Validation F1: 0.354, Learning Rate: 0.09200000000000001\n","EPOCH: 92, Train Loss: 1.970, Valid Loss: 2.851, Validation F1: 0.354, Learning Rate: 0.09300000000000001\n","EPOCH: 93, Train Loss: 2.090, Valid Loss: 3.621, Validation F1: 0.311, Learning Rate: 0.094\n","EPOCH: 94, Train Loss: 1.151, Valid Loss: 0.838, Validation F1: 0.460, Learning Rate: 0.095\n","EPOCH: 95, Train Loss: 1.363, Valid Loss: 4.073, Validation F1: 0.354, Learning Rate: 0.096\n","EPOCH: 96, Train Loss: 1.919, Valid Loss: 1.398, Validation F1: 0.460, Learning Rate: 0.097\n","EPOCH: 97, Train Loss: 2.051, Valid Loss: 0.821, Validation F1: 0.460, Learning Rate: 0.098\n","EPOCH: 98, Train Loss: 1.442, Valid Loss: 0.849, Validation F1: 0.460, Learning Rate: 0.099\n","EPOCH: 99, Train Loss: 1.169, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.1\n","EPOCH: 100, Train Loss: 1.594, Valid Loss: 0.687, Validation F1: 0.460, Learning Rate: 0.1\n","EPOCH: 101, Train Loss: 1.087, Valid Loss: 3.029, Validation F1: 0.354, Learning Rate: 0.09999969538288954\n","EPOCH: 102, Train Loss: 1.506, Valid Loss: 2.307, Validation F1: 0.311, Learning Rate: 0.09999878153526975\n","EPOCH: 103, Train Loss: 1.705, Valid Loss: 1.185, Validation F1: 0.460, Learning Rate: 0.09999725846827562\n","EPOCH: 104, Train Loss: 1.272, Valid Loss: 1.103, Validation F1: 0.311, Learning Rate: 0.09999512620046523\n","EPOCH: 105, Train Loss: 1.119, Valid Loss: 1.102, Validation F1: 0.311, Learning Rate: 0.09999238475781957\n","EPOCH: 106, Train Loss: 1.234, Valid Loss: 1.131, Validation F1: 0.460, Learning Rate: 0.09998903417374227\n","EPOCH: 107, Train Loss: 1.497, Valid Loss: 1.838, Validation F1: 0.354, Learning Rate: 0.09998507448905918\n","EPOCH: 108, Train Loss: 1.612, Valid Loss: 1.366, Validation F1: 0.409, Learning Rate: 0.09998050575201774\n","EPOCH: 109, Train Loss: 1.962, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0999753280182866\n","EPOCH: 110, Train Loss: 1.378, Valid Loss: 2.462, Validation F1: 0.311, Learning Rate: 0.0999695413509548\n","EPOCH: 111, Train Loss: 1.800, Valid Loss: 1.081, Validation F1: 0.311, Learning Rate: 0.09996314582053106\n","EPOCH: 112, Train Loss: 1.778, Valid Loss: 1.626, Validation F1: 0.311, Learning Rate: 0.09995614150494292\n","EPOCH: 113, Train Loss: 1.679, Valid Loss: 0.652, Validation F1: 0.311, Learning Rate: 0.09994852848953575\n","EPOCH: 114, Train Loss: 1.111, Valid Loss: 1.033, Validation F1: 0.311, Learning Rate: 0.09994030686707173\n","EPOCH: 115, Train Loss: 1.414, Valid Loss: 0.848, Validation F1: 0.311, Learning Rate: 0.0999314767377287\n","EPOCH: 116, Train Loss: 1.544, Valid Loss: 0.793, Validation F1: 0.460, Learning Rate: 0.09992203820909906\n","EPOCH: 117, Train Loss: 1.403, Valid Loss: 1.220, Validation F1: 0.460, Learning Rate: 0.09991199139618828\n","EPOCH: 118, Train Loss: 1.722, Valid Loss: 1.390, Validation F1: 0.460, Learning Rate: 0.09990133642141358\n","EPOCH: 119, Train Loss: 1.703, Valid Loss: 1.568, Validation F1: 0.460, Learning Rate: 0.0998900734146025\n","EPOCH: 120, Train Loss: 1.598, Valid Loss: 1.573, Validation F1: 0.460, Learning Rate: 0.09987820251299122\n","EPOCH: 121, Train Loss: 1.310, Valid Loss: 1.885, Validation F1: 0.311, Learning Rate: 0.0998657238612229\n","EPOCH: 122, Train Loss: 1.474, Valid Loss: 1.046, Validation F1: 0.460, Learning Rate: 0.09985263761134602\n","EPOCH: 123, Train Loss: 1.353, Valid Loss: 2.734, Validation F1: 0.354, Learning Rate: 0.09983894392281235\n","EPOCH: 124, Train Loss: 1.251, Valid Loss: 1.606, Validation F1: 0.460, Learning Rate: 0.09982464296247523\n","EPOCH: 125, Train Loss: 1.521, Valid Loss: 0.698, Validation F1: 0.460, Learning Rate: 0.09980973490458728\n","EPOCH: 126, Train Loss: 1.617, Valid Loss: 1.653, Validation F1: 0.460, Learning Rate: 0.09979421993079851\n","EPOCH: 127, Train Loss: 1.143, Valid Loss: 1.649, Validation F1: 0.460, Learning Rate: 0.09977809823015399\n","EPOCH: 128, Train Loss: 1.100, Valid Loss: 2.589, Validation F1: 0.311, Learning Rate: 0.09976136999909156\n","EPOCH: 129, Train Loss: 1.884, Valid Loss: 0.911, Validation F1: 0.311, Learning Rate: 0.09974403544143941\n","EPOCH: 130, Train Loss: 1.295, Valid Loss: 0.997, Validation F1: 0.460, Learning Rate: 0.09972609476841367\n","EPOCH: 131, Train Loss: 1.583, Valid Loss: 0.779, Validation F1: 0.460, Learning Rate: 0.09970754819861577\n","EPOCH: 132, Train Loss: 0.992, Valid Loss: 0.724, Validation F1: 0.460, Learning Rate: 0.09968839595802981\n","EPOCH: 133, Train Loss: 1.613, Valid Loss: 2.487, Validation F1: 0.354, Learning Rate: 0.09966863828001982\n","EPOCH: 134, Train Loss: 1.639, Valid Loss: 1.113, Validation F1: 0.311, Learning Rate: 0.09964827540532684\n","EPOCH: 135, Train Loss: 1.315, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.0996273075820661\n","EPOCH: 136, Train Loss: 1.379, Valid Loss: 0.974, Validation F1: 0.460, Learning Rate: 0.09960573506572389\n","EPOCH: 137, Train Loss: 1.123, Valid Loss: 2.352, Validation F1: 0.354, Learning Rate: 0.09958355811915452\n","EPOCH: 138, Train Loss: 2.305, Valid Loss: 1.565, Validation F1: 0.460, Learning Rate: 0.0995607770125771\n","EPOCH: 139, Train Loss: 1.975, Valid Loss: 1.329, Validation F1: 0.460, Learning Rate: 0.09953739202357217\n","EPOCH: 140, Train Loss: 1.386, Valid Loss: 1.233, Validation F1: 0.311, Learning Rate: 0.09951340343707851\n","EPOCH: 141, Train Loss: 1.754, Valid Loss: 2.060, Validation F1: 0.311, Learning Rate: 0.09948881154538945\n","EPOCH: 142, Train Loss: 1.499, Valid Loss: 0.718, Validation F1: 0.460, Learning Rate: 0.09946361664814941\n","EPOCH: 143, Train Loss: 1.806, Valid Loss: 3.239, Validation F1: 0.354, Learning Rate: 0.0994378190523503\n","EPOCH: 144, Train Loss: 2.070, Valid Loss: 1.922, Validation F1: 0.311, Learning Rate: 0.09941141907232764\n","EPOCH: 145, Train Loss: 1.492, Valid Loss: 3.269, Validation F1: 0.311, Learning Rate: 0.0993844170297569\n","EPOCH: 146, Train Loss: 1.067, Valid Loss: 0.702, Validation F1: 0.460, Learning Rate: 0.09935681325364941\n","EPOCH: 147, Train Loss: 1.367, Valid Loss: 1.406, Validation F1: 0.460, Learning Rate: 0.09932860808034848\n","EPOCH: 148, Train Loss: 1.080, Valid Loss: 1.386, Validation F1: 0.460, Learning Rate: 0.09929980185352526\n","EPOCH: 149, Train Loss: 1.357, Valid Loss: 0.941, Validation F1: 0.311, Learning Rate: 0.09927039492417451\n","EPOCH: 150, Train Loss: 1.334, Valid Loss: 0.878, Validation F1: 0.460, Learning Rate: 0.09924038765061041\n","EPOCH: 151, Train Loss: 1.093, Valid Loss: 0.739, Validation F1: 0.460, Learning Rate: 0.09920978039846211\n","EPOCH: 152, Train Loss: 1.334, Valid Loss: 1.625, Validation F1: 0.460, Learning Rate: 0.09917857354066931\n","EPOCH: 153, Train Loss: 1.728, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.09914676745747772\n","EPOCH: 154, Train Loss: 0.990, Valid Loss: 1.177, Validation F1: 0.311, Learning Rate: 0.09911436253643444\n","EPOCH: 155, Train Loss: 1.220, Valid Loss: 0.715, Validation F1: 0.460, Learning Rate: 0.0990813591723832\n","EPOCH: 156, Train Loss: 1.172, Valid Loss: 0.728, Validation F1: 0.460, Learning Rate: 0.09904775776745958\n","EPOCH: 157, Train Loss: 1.746, Valid Loss: 2.092, Validation F1: 0.354, Learning Rate: 0.0990135587310861\n","EPOCH: 158, Train Loss: 1.452, Valid Loss: 1.486, Validation F1: 0.460, Learning Rate: 0.09897876247996722\n","EPOCH: 159, Train Loss: 1.579, Valid Loss: 0.719, Validation F1: 0.460, Learning Rate: 0.09894336943808427\n","EPOCH: 160, Train Loss: 1.072, Valid Loss: 0.704, Validation F1: 0.460, Learning Rate: 0.09890738003669029\n","EPOCH: 161, Train Loss: 1.197, Valid Loss: 0.714, Validation F1: 0.460, Learning Rate: 0.09887079471430481\n","EPOCH: 162, Train Loss: 1.179, Valid Loss: 0.731, Validation F1: 0.460, Learning Rate: 0.0988336139167084\n","EPOCH: 163, Train Loss: 1.349, Valid Loss: 2.122, Validation F1: 0.460, Learning Rate: 0.09879583809693737\n","EPOCH: 164, Train Loss: 1.262, Valid Loss: 1.281, Validation F1: 0.460, Learning Rate: 0.09875746771527817\n","EPOCH: 165, Train Loss: 1.779, Valid Loss: 0.673, Validation F1: 0.460, Learning Rate: 0.09871850323926178\n","EPOCH: 166, Train Loss: 1.145, Valid Loss: 0.722, Validation F1: 0.460, Learning Rate: 0.09867894514365803\n","EPOCH: 167, Train Loss: 1.186, Valid Loss: 1.359, Validation F1: 0.460, Learning Rate: 0.09863879391046984\n","EPOCH: 168, Train Loss: 1.156, Valid Loss: 3.867, Validation F1: 0.311, Learning Rate: 0.09859805002892733\n","EPOCH: 169, Train Loss: 1.170, Valid Loss: 1.146, Validation F1: 0.460, Learning Rate: 0.09855671399548183\n","EPOCH: 170, Train Loss: 1.846, Valid Loss: 1.462, Validation F1: 0.460, Learning Rate: 0.09851478631379984\n","EPOCH: 171, Train Loss: 1.300, Valid Loss: 1.391, Validation F1: 0.460, Learning Rate: 0.09847226749475696\n","EPOCH: 172, Train Loss: 1.503, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.09842915805643157\n","EPOCH: 173, Train Loss: 1.113, Valid Loss: 2.532, Validation F1: 0.354, Learning Rate: 0.09838545852409858\n","EPOCH: 174, Train Loss: 1.763, Valid Loss: 1.237, Validation F1: 0.460, Learning Rate: 0.09834116943022297\n","EPOCH: 175, Train Loss: 1.356, Valid Loss: 0.977, Validation F1: 0.311, Learning Rate: 0.09829629131445343\n","EPOCH: 176, Train Loss: 1.254, Valid Loss: 1.764, Validation F1: 0.311, Learning Rate: 0.09825082472361557\n","EPOCH: 177, Train Loss: 1.361, Valid Loss: 1.888, Validation F1: 0.311, Learning Rate: 0.09820477021170552\n","EPOCH: 178, Train Loss: 1.279, Valid Loss: 0.810, Validation F1: 0.460, Learning Rate: 0.09815812833988291\n","EPOCH: 179, Train Loss: 1.324, Valid Loss: 1.414, Validation F1: 0.460, Learning Rate: 0.09811089967646427\n","EPOCH: 180, Train Loss: 1.437, Valid Loss: 1.265, Validation F1: 0.460, Learning Rate: 0.09806308479691594\n","EPOCH: 181, Train Loss: 1.516, Valid Loss: 1.342, Validation F1: 0.460, Learning Rate: 0.09801468428384717\n","EPOCH: 182, Train Loss: 1.098, Valid Loss: 2.916, Validation F1: 0.460, Learning Rate: 0.09796569872700289\n","EPOCH: 183, Train Loss: 2.016, Valid Loss: 0.809, Validation F1: 0.311, Learning Rate: 0.09791612872325667\n","EPOCH: 184, Train Loss: 1.156, Valid Loss: 1.500, Validation F1: 0.460, Learning Rate: 0.09786597487660337\n","EPOCH: 185, Train Loss: 1.703, Valid Loss: 1.220, Validation F1: 0.460, Learning Rate: 0.09781523779815178\n","EPOCH: 186, Train Loss: 1.325, Valid Loss: 1.155, Validation F1: 0.460, Learning Rate: 0.09776391810611719\n","EPOCH: 187, Train Loss: 1.082, Valid Loss: 0.935, Validation F1: 0.311, Learning Rate: 0.09771201642581384\n","EPOCH: 188, Train Loss: 0.948, Valid Loss: 0.698, Validation F1: 0.460, Learning Rate: 0.09765953338964735\n","EPOCH: 189, Train Loss: 1.020, Valid Loss: 3.015, Validation F1: 0.311, Learning Rate: 0.09760646963710695\n","EPOCH: 190, Train Loss: 1.866, Valid Loss: 0.640, Validation F1: 0.460, Learning Rate: 0.09755282581475769\n","EPOCH: 191, Train Loss: 1.276, Valid Loss: 1.303, Validation F1: 0.460, Learning Rate: 0.09749860257623263\n","EPOCH: 192, Train Loss: 1.275, Valid Loss: 1.141, Validation F1: 0.460, Learning Rate: 0.09744380058222485\n","EPOCH: 193, Train Loss: 1.219, Valid Loss: 0.676, Validation F1: 0.460, Learning Rate: 0.0973884205004793\n","EPOCH: 194, Train Loss: 0.944, Valid Loss: 0.640, Validation F1: 0.460, Learning Rate: 0.09733246300578483\n","EPOCH: 195, Train Loss: 1.631, Valid Loss: 4.091, Validation F1: 0.311, Learning Rate: 0.09727592877996585\n","EPOCH: 196, Train Loss: 1.866, Valid Loss: 1.365, Validation F1: 0.460, Learning Rate: 0.09721881851187407\n","EPOCH: 197, Train Loss: 1.451, Valid Loss: 3.203, Validation F1: 0.354, Learning Rate: 0.09716113289738004\n","EPOCH: 198, Train Loss: 1.417, Valid Loss: 0.818, Validation F1: 0.311, Learning Rate: 0.09710287263936485\n","EPOCH: 199, Train Loss: 1.097, Valid Loss: 2.315, Validation F1: 0.354, Learning Rate: 0.09704403844771128\n","EPOCH: 200, Train Loss: 1.377, Valid Loss: 1.280, Validation F1: 0.460, Learning Rate: 0.09698463103929543\n","EPOCH: 201, Train Loss: 1.824, Valid Loss: 2.232, Validation F1: 0.354, Learning Rate: 0.0969246511379778\n","EPOCH: 202, Train Loss: 1.756, Valid Loss: 1.116, Validation F1: 0.460, Learning Rate: 0.09686409947459458\n","EPOCH: 203, Train Loss: 1.206, Valid Loss: 1.076, Validation F1: 0.311, Learning Rate: 0.09680297678694867\n","EPOCH: 204, Train Loss: 1.176, Valid Loss: 4.215, Validation F1: 0.311, Learning Rate: 0.09674128381980072\n","EPOCH: 205, Train Loss: 1.725, Valid Loss: 1.216, Validation F1: 0.460, Learning Rate: 0.09667902132486009\n","EPOCH: 206, Train Loss: 1.047, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.0966161900607756\n","EPOCH: 207, Train Loss: 1.306, Valid Loss: 1.859, Validation F1: 0.354, Learning Rate: 0.09655279079312641\n","EPOCH: 208, Train Loss: 1.669, Valid Loss: 0.961, Validation F1: 0.311, Learning Rate: 0.09648882429441258\n","EPOCH: 209, Train Loss: 1.261, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.09642429134404568\n","EPOCH: 210, Train Loss: 1.295, Valid Loss: 1.069, Validation F1: 0.354, Learning Rate: 0.09635919272833937\n","EPOCH: 211, Train Loss: 1.299, Valid Loss: 1.307, Validation F1: 0.354, Learning Rate: 0.09629352924049975\n","EPOCH: 212, Train Loss: 1.202, Valid Loss: 1.075, Validation F1: 0.460, Learning Rate: 0.09622730168061566\n","EPOCH: 213, Train Loss: 1.502, Valid Loss: 0.954, Validation F1: 0.311, Learning Rate: 0.09616051085564904\n","EPOCH: 214, Train Loss: 1.396, Valid Loss: 4.055, Validation F1: 0.311, Learning Rate: 0.09609315757942503\n","EPOCH: 215, Train Loss: 1.092, Valid Loss: 0.799, Validation F1: 0.460, Learning Rate: 0.09602524267262202\n","EPOCH: 216, Train Loss: 0.811, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.09595676696276173\n","EPOCH: 217, Train Loss: 0.981, Valid Loss: 0.680, Validation F1: 0.460, Learning Rate: 0.09588773128419906\n","EPOCH: 218, Train Loss: 1.459, Valid Loss: 2.159, Validation F1: 0.460, Learning Rate: 0.09581813647811198\n","EPOCH: 219, Train Loss: 0.966, Valid Loss: 0.953, Validation F1: 0.311, Learning Rate: 0.09574798339249124\n","EPOCH: 220, Train Loss: 1.110, Valid Loss: 0.779, Validation F1: 0.460, Learning Rate: 0.09567727288213004\n","EPOCH: 221, Train Loss: 1.235, Valid Loss: 1.306, Validation F1: 0.311, Learning Rate: 0.09560600580861366\n","EPOCH: 222, Train Loss: 0.908, Valid Loss: 0.766, Validation F1: 0.311, Learning Rate: 0.09553418304030886\n","EPOCH: 223, Train Loss: 1.425, Valid Loss: 1.905, Validation F1: 0.460, Learning Rate: 0.09546180545235343\n","EPOCH: 224, Train Loss: 1.521, Valid Loss: 2.971, Validation F1: 0.354, Learning Rate: 0.09538887392664544\n","EPOCH: 225, Train Loss: 1.563, Valid Loss: 0.930, Validation F1: 0.460, Learning Rate: 0.0953153893518325\n","EPOCH: 226, Train Loss: 1.203, Valid Loss: 0.891, Validation F1: 0.311, Learning Rate: 0.09524135262330097\n","EPOCH: 227, Train Loss: 1.314, Valid Loss: 1.089, Validation F1: 0.311, Learning Rate: 0.09516676464316504\n","EPOCH: 228, Train Loss: 1.035, Valid Loss: 1.134, Validation F1: 0.460, Learning Rate: 0.09509162632025568\n","EPOCH: 229, Train Loss: 1.477, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.09501593857010966\n","EPOCH: 230, Train Loss: 1.609, Valid Loss: 2.649, Validation F1: 0.354, Learning Rate: 0.09493970231495835\n","EPOCH: 231, Train Loss: 1.559, Valid Loss: 0.948, Validation F1: 0.311, Learning Rate: 0.09486291848371642\n","EPOCH: 232, Train Loss: 1.268, Valid Loss: 1.390, Validation F1: 0.311, Learning Rate: 0.09478558801197064\n","EPOCH: 233, Train Loss: 0.816, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.09470771184196841\n","EPOCH: 234, Train Loss: 1.006, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.09462929092260627\n","EPOCH: 235, Train Loss: 0.922, Valid Loss: 1.644, Validation F1: 0.460, Learning Rate: 0.09455032620941839\n","EPOCH: 236, Train Loss: 1.384, Valid Loss: 0.661, Validation F1: 0.460, Learning Rate: 0.09447081866456487\n","EPOCH: 237, Train Loss: 0.836, Valid Loss: 0.885, Validation F1: 0.311, Learning Rate: 0.09439076925682006\n","EPOCH: 238, Train Loss: 1.596, Valid Loss: 0.677, Validation F1: 0.311, Learning Rate: 0.09431017896156074\n","EPOCH: 239, Train Loss: 0.908, Valid Loss: 0.751, Validation F1: 0.311, Learning Rate: 0.0942290487607542\n","EPOCH: 240, Train Loss: 1.227, Valid Loss: 0.733, Validation F1: 0.311, Learning Rate: 0.09414737964294634\n","EPOCH: 241, Train Loss: 0.920, Valid Loss: 1.017, Validation F1: 0.460, Learning Rate: 0.0940651726032496\n","EPOCH: 242, Train Loss: 1.037, Valid Loss: 1.162, Validation F1: 0.460, Learning Rate: 0.09398242864333083\n","EPOCH: 243, Train Loss: 0.744, Valid Loss: 2.073, Validation F1: 0.311, Learning Rate: 0.09389914877139903\n","EPOCH: 244, Train Loss: 1.455, Valid Loss: 0.827, Validation F1: 0.311, Learning Rate: 0.09381533400219318\n","EPOCH: 245, Train Loss: 0.983, Valid Loss: 2.081, Validation F1: 0.354, Learning Rate: 0.09373098535696978\n","EPOCH: 246, Train Loss: 1.007, Valid Loss: 0.725, Validation F1: 0.460, Learning Rate: 0.09364610386349048\n","EPOCH: 247, Train Loss: 0.905, Valid Loss: 0.725, Validation F1: 0.460, Learning Rate: 0.09356069055600946\n","EPOCH: 248, Train Loss: 1.725, Valid Loss: 1.650, Validation F1: 0.354, Learning Rate: 0.09347474647526095\n","EPOCH: 249, Train Loss: 1.130, Valid Loss: 1.061, Validation F1: 0.311, Learning Rate: 0.09338827266844642\n","EPOCH: 250, Train Loss: 1.124, Valid Loss: 0.856, Validation F1: 0.311, Learning Rate: 0.09330127018922194\n","EPOCH: 251, Train Loss: 1.126, Valid Loss: 0.746, Validation F1: 0.460, Learning Rate: 0.09321374009768524\n","EPOCH: 252, Train Loss: 0.944, Valid Loss: 0.655, Validation F1: 0.460, Learning Rate: 0.09312568346036287\n","EPOCH: 253, Train Loss: 1.174, Valid Loss: 0.783, Validation F1: 0.460, Learning Rate: 0.09303710135019719\n","EPOCH: 254, Train Loss: 0.842, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.09294799484653322\n","EPOCH: 255, Train Loss: 1.063, Valid Loss: 0.676, Validation F1: 0.460, Learning Rate: 0.09285836503510561\n","EPOCH: 256, Train Loss: 1.032, Valid Loss: 1.997, Validation F1: 0.354, Learning Rate: 0.09276821300802535\n","EPOCH: 257, Train Loss: 1.118, Valid Loss: 1.824, Validation F1: 0.311, Learning Rate: 0.09267753986376637\n","EPOCH: 258, Train Loss: 1.076, Valid Loss: 1.182, Validation F1: 0.460, Learning Rate: 0.09258634670715238\n","EPOCH: 259, Train Loss: 0.830, Valid Loss: 0.998, Validation F1: 0.311, Learning Rate: 0.09249463464934321\n","EPOCH: 260, Train Loss: 1.183, Valid Loss: 0.701, Validation F1: 0.460, Learning Rate: 0.0924024048078213\n","EPOCH: 261, Train Loss: 0.799, Valid Loss: 0.715, Validation F1: 0.311, Learning Rate: 0.09230965830637822\n","EPOCH: 262, Train Loss: 0.853, Valid Loss: 0.799, Validation F1: 0.460, Learning Rate: 0.09221639627510075\n","EPOCH: 263, Train Loss: 1.186, Valid Loss: 1.746, Validation F1: 0.354, Learning Rate: 0.09212261985035737\n","EPOCH: 264, Train Loss: 1.436, Valid Loss: 0.663, Validation F1: 0.460, Learning Rate: 0.09202833017478422\n","EPOCH: 265, Train Loss: 0.809, Valid Loss: 0.666, Validation F1: 0.311, Learning Rate: 0.0919335283972712\n","EPOCH: 266, Train Loss: 0.825, Valid Loss: 1.819, Validation F1: 0.354, Learning Rate: 0.09183821567294809\n","EPOCH: 267, Train Loss: 1.109, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.09174239316317033\n","EPOCH: 268, Train Loss: 1.295, Valid Loss: 2.013, Validation F1: 0.354, Learning Rate: 0.09164606203550499\n","EPOCH: 269, Train Loss: 1.020, Valid Loss: 0.820, Validation F1: 0.460, Learning Rate: 0.09154922346371641\n","EPOCH: 270, Train Loss: 1.375, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0914518786277521\n","EPOCH: 271, Train Loss: 0.997, Valid Loss: 1.982, Validation F1: 0.354, Learning Rate: 0.09135402871372811\n","EPOCH: 272, Train Loss: 1.507, Valid Loss: 1.731, Validation F1: 0.354, Learning Rate: 0.09125567491391476\n","EPOCH: 273, Train Loss: 1.221, Valid Loss: 0.980, Validation F1: 0.460, Learning Rate: 0.0911568184267221\n","EPOCH: 274, Train Loss: 0.688, Valid Loss: 1.427, Validation F1: 0.311, Learning Rate: 0.09105746045668522\n","EPOCH: 275, Train Loss: 1.077, Valid Loss: 0.730, Validation F1: 0.311, Learning Rate: 0.0909576022144496\n","EPOCH: 276, Train Loss: 1.066, Valid Loss: 0.761, Validation F1: 0.460, Learning Rate: 0.09085724491675644\n","EPOCH: 277, Train Loss: 1.562, Valid Loss: 1.724, Validation F1: 0.460, Learning Rate: 0.09075638978642772\n","EPOCH: 278, Train Loss: 1.286, Valid Loss: 1.755, Validation F1: 0.460, Learning Rate: 0.0906550380523514\n","EPOCH: 279, Train Loss: 1.474, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.09055319094946634\n","EPOCH: 280, Train Loss: 1.081, Valid Loss: 1.142, Validation F1: 0.460, Learning Rate: 0.09045084971874738\n","EPOCH: 281, Train Loss: 1.654, Valid Loss: 1.720, Validation F1: 0.460, Learning Rate: 0.09034801560719011\n","EPOCH: 282, Train Loss: 1.017, Valid Loss: 1.567, Validation F1: 0.311, Learning Rate: 0.09024468986779571\n","EPOCH: 283, Train Loss: 1.395, Valid Loss: 1.369, Validation F1: 0.311, Learning Rate: 0.09014087375955573\n","EPOCH: 284, Train Loss: 1.052, Valid Loss: 1.129, Validation F1: 0.460, Learning Rate: 0.09003656854743669\n","EPOCH: 285, Train Loss: 1.492, Valid Loss: 2.625, Validation F1: 0.354, Learning Rate: 0.08993177550236464\n","EPOCH: 286, Train Loss: 1.586, Valid Loss: 1.558, Validation F1: 0.311, Learning Rate: 0.08982649590120984\n","EPOCH: 287, Train Loss: 0.901, Valid Loss: 2.216, Validation F1: 0.354, Learning Rate: 0.08972073102677092\n","EPOCH: 288, Train Loss: 1.261, Valid Loss: 0.692, Validation F1: 0.311, Learning Rate: 0.08961448216775954\n","EPOCH: 289, Train Loss: 1.074, Valid Loss: 2.448, Validation F1: 0.354, Learning Rate: 0.08950775061878453\n","EPOCH: 290, Train Loss: 1.344, Valid Loss: 1.879, Validation F1: 0.354, Learning Rate: 0.08940053768033612\n","EPOCH: 291, Train Loss: 0.977, Valid Loss: 0.687, Validation F1: 0.460, Learning Rate: 0.0892928446587701\n","EPOCH: 292, Train Loss: 0.829, Valid Loss: 1.821, Validation F1: 0.354, Learning Rate: 0.089184672866292\n","EPOCH: 293, Train Loss: 1.237, Valid Loss: 0.712, Validation F1: 0.460, Learning Rate: 0.08907602362094096\n","EPOCH: 294, Train Loss: 0.908, Valid Loss: 0.677, Validation F1: 0.311, Learning Rate: 0.08896689824657372\n","EPOCH: 295, Train Loss: 0.966, Valid Loss: 1.885, Validation F1: 0.354, Learning Rate: 0.08885729807284855\n","EPOCH: 296, Train Loss: 1.062, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.088747224435209\n","EPOCH: 297, Train Loss: 0.755, Valid Loss: 2.027, Validation F1: 0.354, Learning Rate: 0.08863667867486756\n","EPOCH: 298, Train Loss: 0.921, Valid Loss: 1.196, Validation F1: 0.311, Learning Rate: 0.08852566213878948\n","EPOCH: 299, Train Loss: 1.002, Valid Loss: 0.736, Validation F1: 0.460, Learning Rate: 0.08841417617967617\n","EPOCH: 300, Train Loss: 1.438, Valid Loss: 1.004, Validation F1: 0.460, Learning Rate: 0.08830222215594892\n","EPOCH: 301, Train Loss: 1.008, Valid Loss: 0.990, Validation F1: 0.460, Learning Rate: 0.08818980143173212\n","EPOCH: 302, Train Loss: 0.899, Valid Loss: 0.686, Validation F1: 0.311, Learning Rate: 0.08807691537683685\n","EPOCH: 303, Train Loss: 0.812, Valid Loss: 1.541, Validation F1: 0.354, Learning Rate: 0.08796356536674406\n","EPOCH: 304, Train Loss: 1.100, Valid Loss: 0.884, Validation F1: 0.460, Learning Rate: 0.08784975278258783\n","EPOCH: 305, Train Loss: 1.350, Valid Loss: 2.548, Validation F1: 0.354, Learning Rate: 0.08773547901113861\n","EPOCH: 306, Train Loss: 1.291, Valid Loss: 1.263, Validation F1: 0.354, Learning Rate: 0.08762074544478622\n","EPOCH: 307, Train Loss: 1.354, Valid Loss: 1.870, Validation F1: 0.354, Learning Rate: 0.08750555348152299\n","EPOCH: 308, Train Loss: 1.027, Valid Loss: 0.693, Validation F1: 0.311, Learning Rate: 0.08738990452492662\n","EPOCH: 309, Train Loss: 0.916, Valid Loss: 0.798, Validation F1: 0.460, Learning Rate: 0.08727379998414311\n","EPOCH: 310, Train Loss: 1.040, Valid Loss: 2.561, Validation F1: 0.354, Learning Rate: 0.08715724127386973\n","EPOCH: 311, Train Loss: 1.785, Valid Loss: 1.285, Validation F1: 0.311, Learning Rate: 0.08704022981433751\n","EPOCH: 312, Train Loss: 0.802, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.0869227670312942\n","EPOCH: 313, Train Loss: 0.912, Valid Loss: 0.724, Validation F1: 0.311, Learning Rate: 0.08680485435598673\n","EPOCH: 314, Train Loss: 0.780, Valid Loss: 0.935, Validation F1: 0.460, Learning Rate: 0.08668649322514382\n","EPOCH: 315, Train Loss: 1.012, Valid Loss: 1.301, Validation F1: 0.311, Learning Rate: 0.08656768508095854\n","EPOCH: 316, Train Loss: 1.085, Valid Loss: 0.706, Validation F1: 0.460, Learning Rate: 0.0864484313710706\n","EPOCH: 317, Train Loss: 1.100, Valid Loss: 1.752, Validation F1: 0.460, Learning Rate: 0.08632873354854881\n","EPOCH: 318, Train Loss: 1.490, Valid Loss: 0.974, Validation F1: 0.460, Learning Rate: 0.0862085930718734\n","EPOCH: 319, Train Loss: 1.020, Valid Loss: 2.991, Validation F1: 0.311, Learning Rate: 0.08608801140491812\n","EPOCH: 320, Train Loss: 1.262, Valid Loss: 2.313, Validation F1: 0.354, Learning Rate: 0.08596699001693257\n","EPOCH: 321, Train Loss: 1.169, Valid Loss: 0.971, Validation F1: 0.460, Learning Rate: 0.08584553038252414\n","EPOCH: 322, Train Loss: 1.278, Valid Loss: 0.847, Validation F1: 0.460, Learning Rate: 0.08572363398164018\n","EPOCH: 323, Train Loss: 1.329, Valid Loss: 1.005, Validation F1: 0.311, Learning Rate: 0.08560130229954983\n","EPOCH: 324, Train Loss: 1.016, Valid Loss: 1.682, Validation F1: 0.311, Learning Rate: 0.08547853682682605\n","EPOCH: 325, Train Loss: 1.126, Valid Loss: 0.681, Validation F1: 0.311, Learning Rate: 0.08535533905932739\n","EPOCH: 326, Train Loss: 1.067, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.08523171049817974\n","EPOCH: 327, Train Loss: 1.060, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.08510765264975813\n","EPOCH: 328, Train Loss: 1.462, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.08498316702566829\n","EPOCH: 329, Train Loss: 0.805, Valid Loss: 0.675, Validation F1: 0.311, Learning Rate: 0.08485825514272824\n","EPOCH: 330, Train Loss: 0.780, Valid Loss: 1.388, Validation F1: 0.460, Learning Rate: 0.08473291852294988\n","EPOCH: 331, Train Loss: 1.536, Valid Loss: 0.641, Validation F1: 0.460, Learning Rate: 0.08460715869352035\n","EPOCH: 332, Train Loss: 0.855, Valid Loss: 1.256, Validation F1: 0.311, Learning Rate: 0.08448097718678349\n","EPOCH: 333, Train Loss: 1.178, Valid Loss: 1.303, Validation F1: 0.311, Learning Rate: 0.08435437554022117\n","EPOCH: 334, Train Loss: 0.930, Valid Loss: 0.775, Validation F1: 0.460, Learning Rate: 0.08422735529643444\n","EPOCH: 335, Train Loss: 1.063, Valid Loss: 0.965, Validation F1: 0.460, Learning Rate: 0.08409991800312494\n","EPOCH: 336, Train Loss: 0.891, Valid Loss: 0.689, Validation F1: 0.311, Learning Rate: 0.08397206521307583\n","EPOCH: 337, Train Loss: 1.008, Valid Loss: 0.736, Validation F1: 0.460, Learning Rate: 0.08384379848413304\n","EPOCH: 338, Train Loss: 1.063, Valid Loss: 1.665, Validation F1: 0.460, Learning Rate: 0.08371511937918619\n","EPOCH: 339, Train Loss: 1.060, Valid Loss: 0.975, Validation F1: 0.460, Learning Rate: 0.08358602946614951\n","EPOCH: 340, Train Loss: 0.946, Valid Loss: 0.908, Validation F1: 0.311, Learning Rate: 0.08345653031794292\n","EPOCH: 341, Train Loss: 1.212, Valid Loss: 2.188, Validation F1: 0.311, Learning Rate: 0.08332662351247262\n","EPOCH: 342, Train Loss: 0.924, Valid Loss: 0.991, Validation F1: 0.460, Learning Rate: 0.08319631063261208\n","EPOCH: 343, Train Loss: 0.905, Valid Loss: 0.861, Validation F1: 0.460, Learning Rate: 0.0830655932661826\n","EPOCH: 344, Train Loss: 0.878, Valid Loss: 1.291, Validation F1: 0.311, Learning Rate: 0.08293447300593403\n","EPOCH: 345, Train Loss: 0.771, Valid Loss: 0.678, Validation F1: 0.311, Learning Rate: 0.08280295144952537\n","EPOCH: 346, Train Loss: 1.119, Valid Loss: 1.619, Validation F1: 0.460, Learning Rate: 0.08267103019950528\n","EPOCH: 347, Train Loss: 1.197, Valid Loss: 2.279, Validation F1: 0.460, Learning Rate: 0.08253871086329255\n","EPOCH: 348, Train Loss: 1.164, Valid Loss: 0.690, Validation F1: 0.311, Learning Rate: 0.08240599505315654\n","EPOCH: 349, Train Loss: 0.749, Valid Loss: 0.872, Validation F1: 0.460, Learning Rate: 0.08227288438619754\n","EPOCH: 350, Train Loss: 1.273, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.08213938048432697\n","EPOCH: 351, Train Loss: 0.735, Valid Loss: 1.029, Validation F1: 0.311, Learning Rate: 0.08200548497424778\n","EPOCH: 352, Train Loss: 0.701, Valid Loss: 0.640, Validation F1: 0.460, Learning Rate: 0.08187119948743449\n","EPOCH: 353, Train Loss: 0.746, Valid Loss: 0.972, Validation F1: 0.460, Learning Rate: 0.08173652566011338\n","EPOCH: 354, Train Loss: 1.097, Valid Loss: 1.407, Validation F1: 0.460, Learning Rate: 0.08160146513324255\n","EPOCH: 355, Train Loss: 0.898, Valid Loss: 1.008, Validation F1: 0.311, Learning Rate: 0.08146601955249189\n","EPOCH: 356, Train Loss: 1.242, Valid Loss: 0.720, Validation F1: 0.311, Learning Rate: 0.08133019056822303\n","EPOCH: 357, Train Loss: 0.826, Valid Loss: 0.950, Validation F1: 0.460, Learning Rate: 0.08119397983546932\n","EPOCH: 358, Train Loss: 0.818, Valid Loss: 0.805, Validation F1: 0.460, Learning Rate: 0.08105738901391552\n","EPOCH: 359, Train Loss: 1.070, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.08092041976787771\n","EPOCH: 360, Train Loss: 1.004, Valid Loss: 1.246, Validation F1: 0.311, Learning Rate: 0.08078307376628291\n","EPOCH: 361, Train Loss: 0.764, Valid Loss: 0.772, Validation F1: 0.460, Learning Rate: 0.08064535268264883\n","EPOCH: 362, Train Loss: 0.826, Valid Loss: 1.077, Validation F1: 0.311, Learning Rate: 0.08050725819506338\n","EPOCH: 363, Train Loss: 0.810, Valid Loss: 1.217, Validation F1: 0.311, Learning Rate: 0.08036879198616434\n","EPOCH: 364, Train Loss: 0.944, Valid Loss: 1.051, Validation F1: 0.311, Learning Rate: 0.08022995574311875\n","EPOCH: 365, Train Loss: 1.411, Valid Loss: 1.255, Validation F1: 0.311, Learning Rate: 0.08009075115760242\n","EPOCH: 366, Train Loss: 0.905, Valid Loss: 1.104, Validation F1: 0.311, Learning Rate: 0.0799511799257793\n","EPOCH: 367, Train Loss: 0.742, Valid Loss: 1.466, Validation F1: 0.460, Learning Rate: 0.0798112437482808\n","EPOCH: 368, Train Loss: 1.306, Valid Loss: 2.253, Validation F1: 0.460, Learning Rate: 0.07967094433018507\n","EPOCH: 369, Train Loss: 1.123, Valid Loss: 0.902, Validation F1: 0.460, Learning Rate: 0.07953028338099627\n","EPOCH: 370, Train Loss: 1.442, Valid Loss: 2.820, Validation F1: 0.354, Learning Rate: 0.07938926261462366\n","EPOCH: 371, Train Loss: 1.237, Valid Loss: 1.910, Validation F1: 0.311, Learning Rate: 0.07924788374936077\n","EPOCH: 372, Train Loss: 0.802, Valid Loss: 0.667, Validation F1: 0.460, Learning Rate: 0.07910614850786447\n","EPOCH: 373, Train Loss: 0.737, Valid Loss: 0.762, Validation F1: 0.460, Learning Rate: 0.07896405861713394\n","EPOCH: 374, Train Loss: 0.972, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.07882161580848966\n","EPOCH: 375, Train Loss: 0.750, Valid Loss: 1.516, Validation F1: 0.460, Learning Rate: 0.07867882181755231\n","EPOCH: 376, Train Loss: 1.037, Valid Loss: 1.027, Validation F1: 0.311, Learning Rate: 0.0785356783842216\n","EPOCH: 377, Train Loss: 1.071, Valid Loss: 2.809, Validation F1: 0.311, Learning Rate: 0.07839218725265507\n","EPOCH: 378, Train Loss: 1.133, Valid Loss: 1.270, Validation F1: 0.460, Learning Rate: 0.0782483501712469\n","EPOCH: 379, Train Loss: 0.867, Valid Loss: 1.199, Validation F1: 0.354, Learning Rate: 0.07810416889260653\n","EPOCH: 380, Train Loss: 0.840, Valid Loss: 0.959, Validation F1: 0.354, Learning Rate: 0.07795964517353735\n","EPOCH: 381, Train Loss: 0.785, Valid Loss: 0.819, Validation F1: 0.311, Learning Rate: 0.07781478077501525\n","EPOCH: 382, Train Loss: 0.705, Valid Loss: 1.171, Validation F1: 0.311, Learning Rate: 0.07766957746216721\n","EPOCH: 383, Train Loss: 1.085, Valid Loss: 0.725, Validation F1: 0.311, Learning Rate: 0.07752403700424977\n","EPOCH: 384, Train Loss: 0.723, Valid Loss: 2.097, Validation F1: 0.354, Learning Rate: 0.07737816117462752\n","EPOCH: 385, Train Loss: 0.890, Valid Loss: 0.704, Validation F1: 0.311, Learning Rate: 0.07723195175075136\n","EPOCH: 386, Train Loss: 1.175, Valid Loss: 1.152, Validation F1: 0.311, Learning Rate: 0.077085410514137\n","EPOCH: 387, Train Loss: 0.979, Valid Loss: 0.641, Validation F1: 0.460, Learning Rate: 0.07693853925034316\n","EPOCH: 388, Train Loss: 0.779, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.07679133974894983\n","EPOCH: 389, Train Loss: 0.735, Valid Loss: 1.749, Validation F1: 0.460, Learning Rate: 0.0766438138035365\n","EPOCH: 390, Train Loss: 0.956, Valid Loss: 1.149, Validation F1: 0.460, Learning Rate: 0.07649596321166025\n","EPOCH: 391, Train Loss: 0.719, Valid Loss: 1.290, Validation F1: 0.311, Learning Rate: 0.07634778977483389\n","EPOCH: 392, Train Loss: 0.860, Valid Loss: 0.903, Validation F1: 0.460, Learning Rate: 0.07619929529850396\n","EPOCH: 393, Train Loss: 1.283, Valid Loss: 2.152, Validation F1: 0.460, Learning Rate: 0.07605048159202883\n","EPOCH: 394, Train Loss: 1.198, Valid Loss: 0.870, Validation F1: 0.460, Learning Rate: 0.07590135046865652\n","EPOCH: 395, Train Loss: 0.818, Valid Loss: 0.665, Validation F1: 0.311, Learning Rate: 0.07575190374550272\n","EPOCH: 396, Train Loss: 0.867, Valid Loss: 0.800, Validation F1: 0.460, Learning Rate: 0.07560214324352858\n","EPOCH: 397, Train Loss: 0.745, Valid Loss: 0.836, Validation F1: 0.460, Learning Rate: 0.07545207078751857\n","EPOCH: 398, Train Loss: 0.766, Valid Loss: 0.706, Validation F1: 0.460, Learning Rate: 0.07530168820605819\n","EPOCH: 399, Train Loss: 0.707, Valid Loss: 1.139, Validation F1: 0.460, Learning Rate: 0.07515099733151176\n","EPOCH: 400, Train Loss: 0.996, Valid Loss: 1.126, Validation F1: 0.460, Learning Rate: 0.07500000000000001\n","EPOCH: 401, Train Loss: 0.967, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.07484869805137777\n","EPOCH: 402, Train Loss: 1.199, Valid Loss: 1.428, Validation F1: 0.460, Learning Rate: 0.07469709332921155\n","EPOCH: 403, Train Loss: 0.934, Valid Loss: 1.908, Validation F1: 0.311, Learning Rate: 0.07454518768075705\n","EPOCH: 404, Train Loss: 0.852, Valid Loss: 1.528, Validation F1: 0.311, Learning Rate: 0.07439298295693664\n","EPOCH: 405, Train Loss: 0.845, Valid Loss: 1.763, Validation F1: 0.311, Learning Rate: 0.07424048101231687\n","EPOCH: 406, Train Loss: 1.355, Valid Loss: 1.060, Validation F1: 0.311, Learning Rate: 0.07408768370508577\n","EPOCH: 407, Train Loss: 0.937, Valid Loss: 1.104, Validation F1: 0.311, Learning Rate: 0.07393459289703035\n","EPOCH: 408, Train Loss: 0.868, Valid Loss: 0.804, Validation F1: 0.460, Learning Rate: 0.07378121045351375\n","EPOCH: 409, Train Loss: 0.848, Valid Loss: 2.149, Validation F1: 0.460, Learning Rate: 0.0736275382434527\n","EPOCH: 410, Train Loss: 1.129, Valid Loss: 0.746, Validation F1: 0.460, Learning Rate: 0.07347357813929455\n","EPOCH: 411, Train Loss: 0.807, Valid Loss: 0.932, Validation F1: 0.460, Learning Rate: 0.07331933201699457\n","EPOCH: 412, Train Loss: 0.741, Valid Loss: 0.658, Validation F1: 0.460, Learning Rate: 0.07316480175599309\n","EPOCH: 413, Train Loss: 0.859, Valid Loss: 1.173, Validation F1: 0.311, Learning Rate: 0.0730099892391926\n","EPOCH: 414, Train Loss: 0.711, Valid Loss: 1.291, Validation F1: 0.460, Learning Rate: 0.07285489635293471\n","EPOCH: 415, Train Loss: 0.826, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.07269952498697733\n","EPOCH: 416, Train Loss: 0.666, Valid Loss: 1.318, Validation F1: 0.311, Learning Rate: 0.07254387703447154\n","EPOCH: 417, Train Loss: 1.059, Valid Loss: 1.839, Validation F1: 0.311, Learning Rate: 0.07238795439193849\n","EPOCH: 418, Train Loss: 1.160, Valid Loss: 0.712, Validation F1: 0.460, Learning Rate: 0.07223175895924637\n","EPOCH: 419, Train Loss: 0.728, Valid Loss: 1.026, Validation F1: 0.311, Learning Rate: 0.07207529263958727\n","EPOCH: 420, Train Loss: 1.110, Valid Loss: 1.944, Validation F1: 0.311, Learning Rate: 0.07191855733945388\n","EPOCH: 421, Train Loss: 0.981, Valid Loss: 1.340, Validation F1: 0.460, Learning Rate: 0.07176155496861639\n","EPOCH: 422, Train Loss: 0.924, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.07160428744009913\n","EPOCH: 423, Train Loss: 0.985, Valid Loss: 0.782, Validation F1: 0.460, Learning Rate: 0.0714467566701573\n","EPOCH: 424, Train Loss: 1.127, Valid Loss: 0.819, Validation F1: 0.460, Learning Rate: 0.07128896457825364\n","EPOCH: 425, Train Loss: 0.733, Valid Loss: 1.094, Validation F1: 0.311, Learning Rate: 0.07113091308703498\n","EPOCH: 426, Train Loss: 0.966, Valid Loss: 1.084, Validation F1: 0.311, Learning Rate: 0.07097260412230887\n","EPOCH: 427, Train Loss: 1.307, Valid Loss: 0.730, Validation F1: 0.311, Learning Rate: 0.07081403961302006\n","EPOCH: 428, Train Loss: 0.688, Valid Loss: 0.787, Validation F1: 0.311, Learning Rate: 0.07065522149122709\n","EPOCH: 429, Train Loss: 0.782, Valid Loss: 0.672, Validation F1: 0.311, Learning Rate: 0.07049615169207864\n","EPOCH: 430, Train Loss: 0.664, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.07033683215379002\n","EPOCH: 431, Train Loss: 0.676, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.07017726481761952\n","EPOCH: 432, Train Loss: 0.732, Valid Loss: 1.070, Validation F1: 0.311, Learning Rate: 0.07001745162784477\n","EPOCH: 433, Train Loss: 0.908, Valid Loss: 1.275, Validation F1: 0.460, Learning Rate: 0.06985739453173903\n","EPOCH: 434, Train Loss: 1.151, Valid Loss: 0.818, Validation F1: 0.460, Learning Rate: 0.06969709547954756\n","EPOCH: 435, Train Loss: 0.756, Valid Loss: 0.676, Validation F1: 0.311, Learning Rate: 0.06953655642446369\n","EPOCH: 436, Train Loss: 0.798, Valid Loss: 1.839, Validation F1: 0.311, Learning Rate: 0.06937577932260515\n","EPOCH: 437, Train Loss: 0.912, Valid Loss: 0.734, Validation F1: 0.460, Learning Rate: 0.06921476613299019\n","EPOCH: 438, Train Loss: 0.775, Valid Loss: 1.191, Validation F1: 0.311, Learning Rate: 0.06905351881751372\n","EPOCH: 439, Train Loss: 0.768, Valid Loss: 0.678, Validation F1: 0.311, Learning Rate: 0.06889203934092336\n","EPOCH: 440, Train Loss: 0.690, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.0687303296707956\n","EPOCH: 441, Train Loss: 0.925, Valid Loss: 1.225, Validation F1: 0.311, Learning Rate: 0.06856839177751176\n","EPOCH: 442, Train Loss: 0.711, Valid Loss: 1.453, Validation F1: 0.311, Learning Rate: 0.06840622763423392\n","EPOCH: 443, Train Loss: 0.800, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.06824383921688097\n","EPOCH: 444, Train Loss: 0.784, Valid Loss: 1.099, Validation F1: 0.311, Learning Rate: 0.06808122850410461\n","EPOCH: 445, Train Loss: 0.877, Valid Loss: 1.010, Validation F1: 0.311, Learning Rate: 0.06791839747726501\n","EPOCH: 446, Train Loss: 0.927, Valid Loss: 0.889, Validation F1: 0.460, Learning Rate: 0.06775534812040687\n","EPOCH: 447, Train Loss: 0.905, Valid Loss: 0.653, Validation F1: 0.311, Learning Rate: 0.06759208242023511\n","EPOCH: 448, Train Loss: 0.763, Valid Loss: 0.725, Validation F1: 0.311, Learning Rate: 0.06742860236609076\n","EPOCH: 449, Train Loss: 0.785, Valid Loss: 0.923, Validation F1: 0.460, Learning Rate: 0.06726490994992673\n","EPOCH: 450, Train Loss: 0.873, Valid Loss: 1.213, Validation F1: 0.311, Learning Rate: 0.06710100716628345\n","EPOCH: 451, Train Loss: 1.054, Valid Loss: 0.691, Validation F1: 0.311, Learning Rate: 0.06693689601226459\n","EPOCH: 452, Train Loss: 0.863, Valid Loss: 0.722, Validation F1: 0.460, Learning Rate: 0.06677257848751277\n","EPOCH: 453, Train Loss: 0.772, Valid Loss: 0.723, Validation F1: 0.311, Learning Rate: 0.06660805659418516\n","EPOCH: 454, Train Loss: 0.851, Valid Loss: 1.085, Validation F1: 0.311, Learning Rate: 0.06644333233692916\n","EPOCH: 455, Train Loss: 0.971, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.06627840772285784\n","EPOCH: 456, Train Loss: 0.777, Valid Loss: 0.791, Validation F1: 0.460, Learning Rate: 0.06611328476152556\n","EPOCH: 457, Train Loss: 1.023, Valid Loss: 0.780, Validation F1: 0.311, Learning Rate: 0.0659479654649035\n","EPOCH: 458, Train Loss: 0.718, Valid Loss: 1.228, Validation F1: 0.460, Learning Rate: 0.06578245184735514\n","EPOCH: 459, Train Loss: 1.191, Valid Loss: 1.271, Validation F1: 0.460, Learning Rate: 0.06561674592561163\n","EPOCH: 460, Train Loss: 0.855, Valid Loss: 0.952, Validation F1: 0.460, Learning Rate: 0.06545084971874737\n","EPOCH: 461, Train Loss: 1.033, Valid Loss: 1.115, Validation F1: 0.354, Learning Rate: 0.06528476524815528\n","EPOCH: 462, Train Loss: 0.830, Valid Loss: 1.023, Validation F1: 0.311, Learning Rate: 0.06511849453752223\n","EPOCH: 463, Train Loss: 1.033, Valid Loss: 1.115, Validation F1: 0.354, Learning Rate: 0.06495203961280434\n","EPOCH: 464, Train Loss: 0.940, Valid Loss: 0.934, Validation F1: 0.354, Learning Rate: 0.06478540250220234\n","EPOCH: 465, Train Loss: 0.872, Valid Loss: 1.216, Validation F1: 0.354, Learning Rate: 0.06461858523613684\n","EPOCH: 466, Train Loss: 0.783, Valid Loss: 0.758, Validation F1: 0.354, Learning Rate: 0.06445158984722359\n","EPOCH: 467, Train Loss: 0.735, Valid Loss: 1.140, Validation F1: 0.354, Learning Rate: 0.06428441837024867\n","EPOCH: 468, Train Loss: 1.388, Valid Loss: 1.695, Validation F1: 0.354, Learning Rate: 0.06411707284214384\n","EPOCH: 469, Train Loss: 0.965, Valid Loss: 1.746, Validation F1: 0.354, Learning Rate: 0.06394955530196147\n","EPOCH: 470, Train Loss: 0.898, Valid Loss: 1.239, Validation F1: 0.354, Learning Rate: 0.06378186779084996\n","EPOCH: 471, Train Loss: 1.013, Valid Loss: 0.661, Validation F1: 0.460, Learning Rate: 0.06361401235202872\n","EPOCH: 472, Train Loss: 0.718, Valid Loss: 0.668, Validation F1: 0.460, Learning Rate: 0.0634459910307633\n","EPOCH: 473, Train Loss: 0.741, Valid Loss: 0.689, Validation F1: 0.460, Learning Rate: 0.06327780587434044\n","EPOCH: 474, Train Loss: 0.743, Valid Loss: 0.865, Validation F1: 0.460, Learning Rate: 0.06310945893204324\n","EPOCH: 475, Train Loss: 0.789, Valid Loss: 0.928, Validation F1: 0.311, Learning Rate: 0.06294095225512604\n","EPOCH: 476, Train Loss: 0.771, Valid Loss: 1.452, Validation F1: 0.311, Learning Rate: 0.06277228789678953\n","EPOCH: 477, Train Loss: 0.739, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.0626034679121557\n","EPOCH: 478, Train Loss: 0.756, Valid Loss: 0.790, Validation F1: 0.460, Learning Rate: 0.062434494358242755\n","EPOCH: 479, Train Loss: 1.144, Valid Loss: 1.184, Validation F1: 0.460, Learning Rate: 0.062265369293940144\n","EPOCH: 480, Train Loss: 0.940, Valid Loss: 1.025, Validation F1: 0.460, Learning Rate: 0.062096094779983395\n","EPOCH: 481, Train Loss: 0.886, Valid Loss: 0.737, Validation F1: 0.460, Learning Rate: 0.06192667287892905\n","EPOCH: 482, Train Loss: 0.866, Valid Loss: 1.188, Validation F1: 0.354, Learning Rate: 0.0617571056551295\n","EPOCH: 483, Train Loss: 0.867, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.06158739517470786\n","EPOCH: 484, Train Loss: 0.661, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.061417543505532794\n","EPOCH: 485, Train Loss: 0.785, Valid Loss: 0.744, Validation F1: 0.460, Learning Rate: 0.06124755271719326\n","EPOCH: 486, Train Loss: 0.746, Valid Loss: 0.660, Validation F1: 0.460, Learning Rate: 0.061077424880973376\n","EPOCH: 487, Train Loss: 0.682, Valid Loss: 0.674, Validation F1: 0.311, Learning Rate: 0.06090716206982714\n","EPOCH: 488, Train Loss: 0.727, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.06073676635835317\n","EPOCH: 489, Train Loss: 0.690, Valid Loss: 0.796, Validation F1: 0.460, Learning Rate: 0.060566239822769444\n","EPOCH: 490, Train Loss: 0.672, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.06039558454088796\n","EPOCH: 491, Train Loss: 0.682, Valid Loss: 0.898, Validation F1: 0.311, Learning Rate: 0.06022480259208951\n","EPOCH: 492, Train Loss: 0.925, Valid Loss: 0.786, Validation F1: 0.311, Learning Rate: 0.060053896057298245\n","EPOCH: 493, Train Loss: 0.815, Valid Loss: 0.715, Validation F1: 0.460, Learning Rate: 0.059882867018956315\n","EPOCH: 494, Train Loss: 0.651, Valid Loss: 0.799, Validation F1: 0.460, Learning Rate: 0.059711717560998606\n","EPOCH: 495, Train Loss: 0.842, Valid Loss: 0.727, Validation F1: 0.460, Learning Rate: 0.05954044976882725\n","EPOCH: 496, Train Loss: 0.870, Valid Loss: 1.126, Validation F1: 0.460, Learning Rate: 0.05936906572928624\n","EPOCH: 497, Train Loss: 0.937, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.059197567530636014\n","EPOCH: 498, Train Loss: 0.745, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.05902595726252801\n","EPOCH: 499, Train Loss: 0.764, Valid Loss: 0.982, Validation F1: 0.460, Learning Rate: 0.05885423701597917\n","EPOCH: 500, Train Loss: 0.728, Valid Loss: 0.813, Validation F1: 0.311, Learning Rate: 0.058682408883346526\n","EPOCH: 501, Train Loss: 0.806, Valid Loss: 1.126, Validation F1: 0.311, Learning Rate: 0.05851047495830163\n","EPOCH: 502, Train Loss: 0.798, Valid Loss: 0.722, Validation F1: 0.460, Learning Rate: 0.05833843733580512\n","EPOCH: 503, Train Loss: 0.743, Valid Loss: 0.947, Validation F1: 0.460, Learning Rate: 0.05816629811208112\n","EPOCH: 504, Train Loss: 0.666, Valid Loss: 0.702, Validation F1: 0.311, Learning Rate: 0.05799405938459175\n","EPOCH: 505, Train Loss: 0.717, Valid Loss: 1.030, Validation F1: 0.311, Learning Rate: 0.05782172325201155\n","EPOCH: 506, Train Loss: 0.972, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.05764929181420191\n","EPOCH: 507, Train Loss: 0.775, Valid Loss: 1.078, Validation F1: 0.460, Learning Rate: 0.057476767172185486\n","EPOCH: 508, Train Loss: 0.760, Valid Loss: 0.827, Validation F1: 0.311, Learning Rate: 0.05730415142812059\n","EPOCH: 509, Train Loss: 0.755, Valid Loss: 1.081, Validation F1: 0.460, Learning Rate: 0.05713144668527559\n","EPOCH: 510, Train Loss: 0.752, Valid Loss: 1.207, Validation F1: 0.311, Learning Rate: 0.05695865504800327\n","EPOCH: 511, Train Loss: 0.954, Valid Loss: 0.915, Validation F1: 0.311, Learning Rate: 0.05678577862171522\n","EPOCH: 512, Train Loss: 0.730, Valid Loss: 0.797, Validation F1: 0.460, Learning Rate: 0.05661281951285613\n","EPOCH: 513, Train Loss: 0.750, Valid Loss: 0.716, Validation F1: 0.311, Learning Rate: 0.05643977982887815\n","EPOCH: 514, Train Loss: 0.706, Valid Loss: 1.338, Validation F1: 0.311, Learning Rate: 0.056266661678215216\n","EPOCH: 515, Train Loss: 0.843, Valid Loss: 0.718, Validation F1: 0.460, Learning Rate: 0.05609346717025737\n","EPOCH: 516, Train Loss: 0.701, Valid Loss: 0.778, Validation F1: 0.311, Learning Rate: 0.05592019841532506\n","EPOCH: 517, Train Loss: 0.738, Valid Loss: 1.120, Validation F1: 0.460, Learning Rate: 0.05574685752464334\n","EPOCH: 518, Train Loss: 0.945, Valid Loss: 0.706, Validation F1: 0.460, Learning Rate: 0.05557344661031627\n","EPOCH: 519, Train Loss: 0.713, Valid Loss: 0.664, Validation F1: 0.460, Learning Rate: 0.055399967785301145\n","EPOCH: 520, Train Loss: 0.769, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.05522642316338268\n","EPOCH: 521, Train Loss: 0.677, Valid Loss: 0.798, Validation F1: 0.460, Learning Rate: 0.055052814859147314\n","EPOCH: 522, Train Loss: 0.802, Valid Loss: 1.303, Validation F1: 0.460, Learning Rate: 0.05487914498795748\n","EPOCH: 523, Train Loss: 0.911, Valid Loss: 0.905, Validation F1: 0.311, Learning Rate: 0.05470541566592573\n","EPOCH: 524, Train Loss: 0.707, Valid Loss: 1.194, Validation F1: 0.460, Learning Rate: 0.05453162900988902\n","EPOCH: 525, Train Loss: 0.907, Valid Loss: 1.341, Validation F1: 0.354, Learning Rate: 0.05435778713738292\n","EPOCH: 526, Train Loss: 0.906, Valid Loss: 0.667, Validation F1: 0.311, Learning Rate: 0.05418389216661579\n","EPOCH: 527, Train Loss: 0.687, Valid Loss: 0.675, Validation F1: 0.311, Learning Rate: 0.05400994621644294\n","EPOCH: 528, Train Loss: 0.712, Valid Loss: 1.017, Validation F1: 0.354, Learning Rate: 0.05383595140634093\n","EPOCH: 529, Train Loss: 0.816, Valid Loss: 1.143, Validation F1: 0.311, Learning Rate: 0.053661909856381584\n","EPOCH: 530, Train Loss: 0.903, Valid Loss: 1.883, Validation F1: 0.354, Learning Rate: 0.05348782368720626\n","EPOCH: 531, Train Loss: 1.002, Valid Loss: 0.658, Validation F1: 0.460, Learning Rate: 0.053313695020000024\n","EPOCH: 532, Train Loss: 0.694, Valid Loss: 1.257, Validation F1: 0.311, Learning Rate: 0.05313952597646568\n","EPOCH: 533, Train Loss: 1.083, Valid Loss: 0.791, Validation F1: 0.460, Learning Rate: 0.05296531867879809\n","EPOCH: 534, Train Loss: 0.728, Valid Loss: 1.176, Validation F1: 0.311, Learning Rate: 0.0527910752496582\n","EPOCH: 535, Train Loss: 0.735, Valid Loss: 0.886, Validation F1: 0.460, Learning Rate: 0.052616797812147204\n","EPOCH: 536, Train Loss: 0.789, Valid Loss: 0.742, Validation F1: 0.311, Learning Rate: 0.05244248848978067\n","EPOCH: 537, Train Loss: 0.896, Valid Loss: 1.001, Validation F1: 0.460, Learning Rate: 0.05226814940646268\n","EPOCH: 538, Train Loss: 0.806, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.05209378268645998\n","EPOCH: 539, Train Loss: 0.813, Valid Loss: 0.689, Validation F1: 0.460, Learning Rate: 0.051919390454376005\n","EPOCH: 540, Train Loss: 0.714, Valid Loss: 0.830, Validation F1: 0.311, Learning Rate: 0.05174497483512506\n","EPOCH: 541, Train Loss: 0.677, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.051570537953906426\n","EPOCH: 542, Train Loss: 0.734, Valid Loss: 0.906, Validation F1: 0.460, Learning Rate: 0.05139608193617845\n","EPOCH: 543, Train Loss: 0.694, Valid Loss: 0.694, Validation F1: 0.311, Learning Rate: 0.051221608907632665\n","EPOCH: 544, Train Loss: 0.686, Valid Loss: 0.902, Validation F1: 0.460, Learning Rate: 0.051047120994167854\n","EPOCH: 545, Train Loss: 0.810, Valid Loss: 0.943, Validation F1: 0.460, Learning Rate: 0.05087262032186418\n","EPOCH: 546, Train Loss: 0.804, Valid Loss: 0.795, Validation F1: 0.311, Learning Rate: 0.050698109016957274\n","EPOCH: 547, Train Loss: 0.709, Valid Loss: 0.811, Validation F1: 0.311, Learning Rate: 0.05052358920581229\n","EPOCH: 548, Train Loss: 0.688, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.05034906301489808\n","EPOCH: 549, Train Loss: 0.693, Valid Loss: 0.743, Validation F1: 0.311, Learning Rate: 0.05017453257076119\n","EPOCH: 550, Train Loss: 0.788, Valid Loss: 0.795, Validation F1: 0.311, Learning Rate: 0.05\n","EPOCH: 551, Train Loss: 0.728, Valid Loss: 0.757, Validation F1: 0.311, Learning Rate: 0.04982546742923883\n","EPOCH: 552, Train Loss: 0.689, Valid Loss: 0.849, Validation F1: 0.460, Learning Rate: 0.04965093698510192\n","EPOCH: 553, Train Loss: 0.824, Valid Loss: 1.093, Validation F1: 0.311, Learning Rate: 0.04947641079418773\n","EPOCH: 554, Train Loss: 0.863, Valid Loss: 0.641, Validation F1: 0.460, Learning Rate: 0.049301890983042745\n","EPOCH: 555, Train Loss: 0.692, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.049127379678135824\n","EPOCH: 556, Train Loss: 0.708, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.04895287900583216\n","EPOCH: 557, Train Loss: 0.716, Valid Loss: 0.918, Validation F1: 0.460, Learning Rate: 0.04877839109236735\n","EPOCH: 558, Train Loss: 0.761, Valid Loss: 0.931, Validation F1: 0.460, Learning Rate: 0.04860391806382157\n","EPOCH: 559, Train Loss: 0.696, Valid Loss: 0.891, Validation F1: 0.460, Learning Rate: 0.04842946204609359\n","EPOCH: 560, Train Loss: 0.705, Valid Loss: 0.671, Validation F1: 0.460, Learning Rate: 0.04825502516487497\n","EPOCH: 561, Train Loss: 0.702, Valid Loss: 0.885, Validation F1: 0.460, Learning Rate: 0.04808060954562401\n","EPOCH: 562, Train Loss: 0.729, Valid Loss: 0.799, Validation F1: 0.460, Learning Rate: 0.04790621731354003\n","EPOCH: 563, Train Loss: 0.767, Valid Loss: 0.663, Validation F1: 0.460, Learning Rate: 0.047731850593537316\n","EPOCH: 564, Train Loss: 0.742, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.047557511510219336\n","EPOCH: 565, Train Loss: 0.672, Valid Loss: 0.876, Validation F1: 0.460, Learning Rate: 0.04738320218785281\n","EPOCH: 566, Train Loss: 0.895, Valid Loss: 1.320, Validation F1: 0.311, Learning Rate: 0.04720892475034181\n","EPOCH: 567, Train Loss: 0.991, Valid Loss: 1.705, Validation F1: 0.354, Learning Rate: 0.04703468132120193\n","EPOCH: 568, Train Loss: 0.900, Valid Loss: 0.674, Validation F1: 0.460, Learning Rate: 0.04686047402353433\n","EPOCH: 569, Train Loss: 0.729, Valid Loss: 0.913, Validation F1: 0.354, Learning Rate: 0.04668630498000001\n","EPOCH: 570, Train Loss: 0.730, Valid Loss: 0.756, Validation F1: 0.311, Learning Rate: 0.04651217631279374\n","EPOCH: 571, Train Loss: 0.843, Valid Loss: 0.822, Validation F1: 0.354, Learning Rate: 0.04633809014361843\n","EPOCH: 572, Train Loss: 0.758, Valid Loss: 0.894, Validation F1: 0.311, Learning Rate: 0.04616404859365907\n","EPOCH: 573, Train Loss: 0.744, Valid Loss: 0.858, Validation F1: 0.460, Learning Rate: 0.04599005378355706\n","EPOCH: 574, Train Loss: 0.716, Valid Loss: 1.046, Validation F1: 0.311, Learning Rate: 0.04581610783338424\n","EPOCH: 575, Train Loss: 0.809, Valid Loss: 0.981, Validation F1: 0.460, Learning Rate: 0.04564221286261709\n","EPOCH: 576, Train Loss: 0.753, Valid Loss: 1.045, Validation F1: 0.311, Learning Rate: 0.045468370990111\n","EPOCH: 577, Train Loss: 0.763, Valid Loss: 0.656, Validation F1: 0.460, Learning Rate: 0.04529458433407428\n","EPOCH: 578, Train Loss: 0.791, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.045120855012042535\n","EPOCH: 579, Train Loss: 0.720, Valid Loss: 0.754, Validation F1: 0.311, Learning Rate: 0.044947185140852684\n","EPOCH: 580, Train Loss: 0.780, Valid Loss: 0.815, Validation F1: 0.460, Learning Rate: 0.04477357683661734\n","EPOCH: 581, Train Loss: 0.751, Valid Loss: 0.762, Validation F1: 0.311, Learning Rate: 0.044600032214698854\n","EPOCH: 582, Train Loss: 0.672, Valid Loss: 1.114, Validation F1: 0.311, Learning Rate: 0.04442655338968374\n","EPOCH: 583, Train Loss: 0.932, Valid Loss: 1.275, Validation F1: 0.354, Learning Rate: 0.04425314247535668\n","EPOCH: 584, Train Loss: 0.851, Valid Loss: 0.876, Validation F1: 0.460, Learning Rate: 0.04407980158467495\n","EPOCH: 585, Train Loss: 0.756, Valid Loss: 0.769, Validation F1: 0.311, Learning Rate: 0.043906532829742634\n","EPOCH: 586, Train Loss: 0.810, Valid Loss: 0.870, Validation F1: 0.460, Learning Rate: 0.04373333832178478\n","EPOCH: 587, Train Loss: 0.831, Valid Loss: 1.154, Validation F1: 0.460, Learning Rate: 0.04356022017112187\n","EPOCH: 588, Train Loss: 0.880, Valid Loss: 0.777, Validation F1: 0.311, Learning Rate: 0.04338718048714388\n","EPOCH: 589, Train Loss: 0.698, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.04321422137828479\n","EPOCH: 590, Train Loss: 0.795, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.04304134495199674\n","EPOCH: 591, Train Loss: 0.736, Valid Loss: 0.762, Validation F1: 0.460, Learning Rate: 0.042868553314724424\n","EPOCH: 592, Train Loss: 0.678, Valid Loss: 1.089, Validation F1: 0.354, Learning Rate: 0.04269584857187943\n","EPOCH: 593, Train Loss: 0.942, Valid Loss: 0.739, Validation F1: 0.460, Learning Rate: 0.04252323282781453\n","EPOCH: 594, Train Loss: 0.851, Valid Loss: 1.096, Validation F1: 0.354, Learning Rate: 0.0423507081857981\n","EPOCH: 595, Train Loss: 0.808, Valid Loss: 0.788, Validation F1: 0.354, Learning Rate: 0.04217827674798845\n","EPOCH: 596, Train Loss: 0.870, Valid Loss: 0.822, Validation F1: 0.354, Learning Rate: 0.042005940615408265\n","EPOCH: 597, Train Loss: 0.753, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.041833701887918906\n","EPOCH: 598, Train Loss: 0.694, Valid Loss: 1.128, Validation F1: 0.311, Learning Rate: 0.04166156266419489\n","EPOCH: 599, Train Loss: 0.726, Valid Loss: 1.008, Validation F1: 0.311, Learning Rate: 0.04148952504169839\n","EPOCH: 600, Train Loss: 0.848, Valid Loss: 1.042, Validation F1: 0.460, Learning Rate: 0.041317591116653486\n","EPOCH: 601, Train Loss: 0.810, Valid Loss: 0.826, Validation F1: 0.460, Learning Rate: 0.04114576298402084\n","EPOCH: 602, Train Loss: 0.674, Valid Loss: 0.796, Validation F1: 0.460, Learning Rate: 0.040974042737472\n","EPOCH: 603, Train Loss: 0.756, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.04080243246936399\n","EPOCH: 604, Train Loss: 0.750, Valid Loss: 0.742, Validation F1: 0.460, Learning Rate: 0.040630934270713764\n","EPOCH: 605, Train Loss: 0.709, Valid Loss: 0.805, Validation F1: 0.460, Learning Rate: 0.04045955023117276\n","EPOCH: 606, Train Loss: 0.722, Valid Loss: 0.744, Validation F1: 0.311, Learning Rate: 0.04028828243900141\n","EPOCH: 607, Train Loss: 0.726, Valid Loss: 0.660, Validation F1: 0.460, Learning Rate: 0.04011713298104369\n","EPOCH: 608, Train Loss: 0.688, Valid Loss: 0.656, Validation F1: 0.460, Learning Rate: 0.03994610394270178\n","EPOCH: 609, Train Loss: 0.777, Valid Loss: 0.820, Validation F1: 0.460, Learning Rate: 0.03977519740791048\n","EPOCH: 610, Train Loss: 0.755, Valid Loss: 0.746, Validation F1: 0.460, Learning Rate: 0.039604415459112044\n","EPOCH: 611, Train Loss: 0.713, Valid Loss: 0.782, Validation F1: 0.460, Learning Rate: 0.03943376017723057\n","EPOCH: 612, Train Loss: 0.725, Valid Loss: 0.805, Validation F1: 0.460, Learning Rate: 0.03926323364164684\n","EPOCH: 613, Train Loss: 0.746, Valid Loss: 1.007, Validation F1: 0.354, Learning Rate: 0.03909283793017288\n","EPOCH: 614, Train Loss: 0.770, Valid Loss: 0.745, Validation F1: 0.311, Learning Rate: 0.03892257511902664\n","EPOCH: 615, Train Loss: 0.779, Valid Loss: 0.656, Validation F1: 0.460, Learning Rate: 0.03875244728280676\n","EPOCH: 616, Train Loss: 0.739, Valid Loss: 0.750, Validation F1: 0.460, Learning Rate: 0.03858245649446721\n","EPOCH: 617, Train Loss: 0.751, Valid Loss: 0.660, Validation F1: 0.460, Learning Rate: 0.03841260482529214\n","EPOCH: 618, Train Loss: 0.675, Valid Loss: 0.655, Validation F1: 0.460, Learning Rate: 0.03824289434487049\n","EPOCH: 619, Train Loss: 0.705, Valid Loss: 1.010, Validation F1: 0.311, Learning Rate: 0.03807332712107097\n","EPOCH: 620, Train Loss: 0.691, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.037903905220016625\n","EPOCH: 621, Train Loss: 0.721, Valid Loss: 0.730, Validation F1: 0.311, Learning Rate: 0.03773463070605987\n","EPOCH: 622, Train Loss: 0.667, Valid Loss: 0.778, Validation F1: 0.460, Learning Rate: 0.03756550564175727\n","EPOCH: 623, Train Loss: 0.709, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.03739653208784432\n","EPOCH: 624, Train Loss: 0.635, Valid Loss: 0.779, Validation F1: 0.460, Learning Rate: 0.03722771210321048\n","EPOCH: 625, Train Loss: 0.709, Valid Loss: 0.720, Validation F1: 0.311, Learning Rate: 0.03705904774487395\n","EPOCH: 626, Train Loss: 0.673, Valid Loss: 0.981, Validation F1: 0.311, Learning Rate: 0.03689054106795677\n","EPOCH: 627, Train Loss: 0.720, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.03672219412565956\n","EPOCH: 628, Train Loss: 0.776, Valid Loss: 1.301, Validation F1: 0.460, Learning Rate: 0.03655400896923672\n","EPOCH: 629, Train Loss: 0.993, Valid Loss: 0.716, Validation F1: 0.460, Learning Rate: 0.03638598764797129\n","EPOCH: 630, Train Loss: 0.694, Valid Loss: 0.775, Validation F1: 0.460, Learning Rate: 0.036218132209150045\n","EPOCH: 631, Train Loss: 0.750, Valid Loss: 0.740, Validation F1: 0.311, Learning Rate: 0.036050444698038545\n","EPOCH: 632, Train Loss: 0.718, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.035882927157856175\n","EPOCH: 633, Train Loss: 0.788, Valid Loss: 1.061, Validation F1: 0.354, Learning Rate: 0.035715581629751324\n","EPOCH: 634, Train Loss: 0.802, Valid Loss: 0.809, Validation F1: 0.311, Learning Rate: 0.03554841015277641\n","EPOCH: 635, Train Loss: 0.690, Valid Loss: 0.776, Validation F1: 0.460, Learning Rate: 0.03538141476386317\n","EPOCH: 636, Train Loss: 0.840, Valid Loss: 1.407, Validation F1: 0.311, Learning Rate: 0.03521459749779768\n","EPOCH: 637, Train Loss: 0.775, Valid Loss: 1.033, Validation F1: 0.460, Learning Rate: 0.03504796038719567\n","EPOCH: 638, Train Loss: 0.733, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.03488150546247778\n","EPOCH: 639, Train Loss: 0.772, Valid Loss: 0.721, Validation F1: 0.460, Learning Rate: 0.034715234751844716\n","EPOCH: 640, Train Loss: 0.717, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.034549150281252626\n","EPOCH: 641, Train Loss: 0.691, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.034383254074388366\n","EPOCH: 642, Train Loss: 0.785, Valid Loss: 0.917, Validation F1: 0.460, Learning Rate: 0.034217548152644876\n","EPOCH: 643, Train Loss: 0.690, Valid Loss: 0.982, Validation F1: 0.311, Learning Rate: 0.0340520345350965\n","EPOCH: 644, Train Loss: 0.785, Valid Loss: 1.328, Validation F1: 0.311, Learning Rate: 0.033886715238474446\n","EPOCH: 645, Train Loss: 0.764, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.03372159227714218\n","EPOCH: 646, Train Loss: 0.752, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.03355666766307084\n","EPOCH: 647, Train Loss: 0.667, Valid Loss: 0.758, Validation F1: 0.460, Learning Rate: 0.03339194340581485\n","EPOCH: 648, Train Loss: 0.786, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.03322742151248725\n","EPOCH: 649, Train Loss: 0.677, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.03306310398773543\n","EPOCH: 650, Train Loss: 0.721, Valid Loss: 0.715, Validation F1: 0.311, Learning Rate: 0.03289899283371656\n","EPOCH: 651, Train Loss: 0.755, Valid Loss: 0.709, Validation F1: 0.311, Learning Rate: 0.032735090050073266\n","EPOCH: 652, Train Loss: 0.669, Valid Loss: 0.757, Validation F1: 0.460, Learning Rate: 0.03257139763390925\n","EPOCH: 653, Train Loss: 0.684, Valid Loss: 0.948, Validation F1: 0.311, Learning Rate: 0.03240791757976491\n","EPOCH: 654, Train Loss: 0.784, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.032244651879593154\n","EPOCH: 655, Train Loss: 0.746, Valid Loss: 0.713, Validation F1: 0.460, Learning Rate: 0.03208160252273499\n","EPOCH: 656, Train Loss: 0.787, Valid Loss: 0.786, Validation F1: 0.311, Learning Rate: 0.03191877149589539\n","EPOCH: 657, Train Loss: 0.708, Valid Loss: 0.680, Validation F1: 0.460, Learning Rate: 0.03175616078311901\n","EPOCH: 658, Train Loss: 0.741, Valid Loss: 0.960, Validation F1: 0.460, Learning Rate: 0.0315937723657661\n","EPOCH: 659, Train Loss: 0.740, Valid Loss: 0.747, Validation F1: 0.460, Learning Rate: 0.03143160822248827\n","EPOCH: 660, Train Loss: 0.731, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0312696703292044\n","EPOCH: 661, Train Loss: 0.669, Valid Loss: 0.713, Validation F1: 0.311, Learning Rate: 0.03110796065907665\n","EPOCH: 662, Train Loss: 0.677, Valid Loss: 0.709, Validation F1: 0.311, Learning Rate: 0.03094648118248629\n","EPOCH: 663, Train Loss: 0.681, Valid Loss: 0.703, Validation F1: 0.311, Learning Rate: 0.03078523386700982\n","EPOCH: 664, Train Loss: 0.684, Valid Loss: 0.708, Validation F1: 0.311, Learning Rate: 0.03062422067739485\n","EPOCH: 665, Train Loss: 0.713, Valid Loss: 0.897, Validation F1: 0.311, Learning Rate: 0.03046344357553632\n","EPOCH: 666, Train Loss: 0.663, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.03030290452045244\n","EPOCH: 667, Train Loss: 0.714, Valid Loss: 0.701, Validation F1: 0.311, Learning Rate: 0.030142605468260975\n","EPOCH: 668, Train Loss: 0.687, Valid Loss: 0.908, Validation F1: 0.311, Learning Rate: 0.029982548372155263\n","EPOCH: 669, Train Loss: 0.777, Valid Loss: 0.893, Validation F1: 0.460, Learning Rate: 0.029822735182380496\n","EPOCH: 670, Train Loss: 0.838, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.029663167846209995\n","EPOCH: 671, Train Loss: 0.717, Valid Loss: 0.713, Validation F1: 0.460, Learning Rate: 0.029503848307921354\n","EPOCH: 672, Train Loss: 0.744, Valid Loss: 0.712, Validation F1: 0.460, Learning Rate: 0.029344778508772918\n","EPOCH: 673, Train Loss: 0.704, Valid Loss: 0.711, Validation F1: 0.311, Learning Rate: 0.02918596038697995\n","EPOCH: 674, Train Loss: 0.674, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.029027395877691143\n","EPOCH: 675, Train Loss: 0.709, Valid Loss: 0.709, Validation F1: 0.460, Learning Rate: 0.02886908691296504\n","EPOCH: 676, Train Loss: 0.699, Valid Loss: 0.718, Validation F1: 0.460, Learning Rate: 0.028711035421746363\n","EPOCH: 677, Train Loss: 0.695, Valid Loss: 0.710, Validation F1: 0.460, Learning Rate: 0.02855324332984271\n","EPOCH: 678, Train Loss: 0.677, Valid Loss: 0.714, Validation F1: 0.311, Learning Rate: 0.02839571255990088\n","EPOCH: 679, Train Loss: 0.728, Valid Loss: 0.874, Validation F1: 0.460, Learning Rate: 0.028238445031383633\n","EPOCH: 680, Train Loss: 0.707, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.028081442660546126\n","EPOCH: 681, Train Loss: 0.684, Valid Loss: 0.697, Validation F1: 0.311, Learning Rate: 0.027924707360412748\n","EPOCH: 682, Train Loss: 0.696, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.02776824104075364\n","EPOCH: 683, Train Loss: 0.698, Valid Loss: 0.901, Validation F1: 0.311, Learning Rate: 0.02761204560806152\n","EPOCH: 684, Train Loss: 0.734, Valid Loss: 0.877, Validation F1: 0.311, Learning Rate: 0.027456122965528476\n","EPOCH: 685, Train Loss: 0.686, Valid Loss: 0.685, Validation F1: 0.311, Learning Rate: 0.027300475013022664\n","EPOCH: 686, Train Loss: 0.711, Valid Loss: 0.722, Validation F1: 0.460, Learning Rate: 0.027145103647065308\n","EPOCH: 687, Train Loss: 0.653, Valid Loss: 0.915, Validation F1: 0.311, Learning Rate: 0.026990010760807426\n","EPOCH: 688, Train Loss: 0.770, Valid Loss: 0.679, Validation F1: 0.311, Learning Rate: 0.02683519824400693\n","EPOCH: 689, Train Loss: 0.668, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.026680667983005446\n","EPOCH: 690, Train Loss: 0.691, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.026526421860705474\n","EPOCH: 691, Train Loss: 0.688, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.026372461756547307\n","EPOCH: 692, Train Loss: 0.671, Valid Loss: 0.710, Validation F1: 0.311, Learning Rate: 0.026218789546486234\n","EPOCH: 693, Train Loss: 0.685, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.026065407102969663\n","EPOCH: 694, Train Loss: 0.670, Valid Loss: 0.685, Validation F1: 0.311, Learning Rate: 0.02591231629491423\n","EPOCH: 695, Train Loss: 0.875, Valid Loss: 0.809, Validation F1: 0.460, Learning Rate: 0.025759518987683156\n","EPOCH: 696, Train Loss: 0.718, Valid Loss: 0.705, Validation F1: 0.311, Learning Rate: 0.025607017043063365\n","EPOCH: 697, Train Loss: 0.677, Valid Loss: 0.845, Validation F1: 0.311, Learning Rate: 0.025454812319242966\n","EPOCH: 698, Train Loss: 0.707, Valid Loss: 0.879, Validation F1: 0.311, Learning Rate: 0.025302906670788466\n","EPOCH: 699, Train Loss: 0.706, Valid Loss: 0.696, Validation F1: 0.311, Learning Rate: 0.02515130194862224\n","EPOCH: 700, Train Loss: 0.661, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.025000000000000012\n","EPOCH: 701, Train Loss: 0.688, Valid Loss: 0.690, Validation F1: 0.311, Learning Rate: 0.024849002668488253\n","EPOCH: 702, Train Loss: 0.688, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.024698311793941826\n","EPOCH: 703, Train Loss: 0.676, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.024547929212481442\n","EPOCH: 704, Train Loss: 0.682, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.024397856756471437\n","EPOCH: 705, Train Loss: 0.666, Valid Loss: 0.670, Validation F1: 0.460, Learning Rate: 0.024248096254497295\n","EPOCH: 706, Train Loss: 0.682, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.024098649531343504\n","EPOCH: 707, Train Loss: 0.686, Valid Loss: 0.704, Validation F1: 0.311, Learning Rate: 0.023949518407971205\n","EPOCH: 708, Train Loss: 0.682, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.023800704701496058\n","EPOCH: 709, Train Loss: 0.705, Valid Loss: 0.705, Validation F1: 0.460, Learning Rate: 0.02365221022516613\n","EPOCH: 710, Train Loss: 0.654, Valid Loss: 0.696, Validation F1: 0.460, Learning Rate: 0.023504036788339767\n","EPOCH: 711, Train Loss: 0.696, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.023356186196463503\n","EPOCH: 712, Train Loss: 0.689, Valid Loss: 0.683, Validation F1: 0.460, Learning Rate: 0.023208660251050162\n","EPOCH: 713, Train Loss: 0.670, Valid Loss: 0.738, Validation F1: 0.311, Learning Rate: 0.023061460749656856\n","EPOCH: 714, Train Loss: 0.707, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.02291458948586302\n","EPOCH: 715, Train Loss: 0.677, Valid Loss: 0.709, Validation F1: 0.460, Learning Rate: 0.022768048249248652\n","EPOCH: 716, Train Loss: 0.713, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.022621838825372498\n","EPOCH: 717, Train Loss: 0.769, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.022475962995750227\n","EPOCH: 718, Train Loss: 0.749, Valid Loss: 0.663, Validation F1: 0.460, Learning Rate: 0.02233042253783281\n","EPOCH: 719, Train Loss: 0.672, Valid Loss: 0.697, Validation F1: 0.460, Learning Rate: 0.022185219224984766\n","EPOCH: 720, Train Loss: 0.680, Valid Loss: 0.713, Validation F1: 0.311, Learning Rate: 0.022040354826462674\n","EPOCH: 721, Train Loss: 0.673, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.021895831107393494\n","EPOCH: 722, Train Loss: 0.683, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.02175164982875312\n","EPOCH: 723, Train Loss: 0.680, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.021607812747344957\n","EPOCH: 724, Train Loss: 0.663, Valid Loss: 0.692, Validation F1: 0.460, Learning Rate: 0.021464321615778426\n","EPOCH: 725, Train Loss: 0.683, Valid Loss: 0.689, Validation F1: 0.311, Learning Rate: 0.021321178182447716\n","EPOCH: 726, Train Loss: 0.679, Valid Loss: 0.781, Validation F1: 0.311, Learning Rate: 0.021178384191510347\n","EPOCH: 727, Train Loss: 0.765, Valid Loss: 0.699, Validation F1: 0.311, Learning Rate: 0.02103594138286608\n","EPOCH: 728, Train Loss: 0.671, Valid Loss: 0.683, Validation F1: 0.460, Learning Rate: 0.020893851492135542\n","EPOCH: 729, Train Loss: 0.749, Valid Loss: 0.672, Validation F1: 0.460, Learning Rate: 0.020752116250639233\n","EPOCH: 730, Train Loss: 0.731, Valid Loss: 0.810, Validation F1: 0.460, Learning Rate: 0.020610737385376356\n","EPOCH: 731, Train Loss: 0.722, Valid Loss: 0.683, Validation F1: 0.460, Learning Rate: 0.020469716619003733\n","EPOCH: 732, Train Loss: 0.692, Valid Loss: 0.790, Validation F1: 0.460, Learning Rate: 0.02032905566981494\n","EPOCH: 733, Train Loss: 0.722, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.02018875625171921\n","EPOCH: 734, Train Loss: 0.697, Valid Loss: 0.709, Validation F1: 0.311, Learning Rate: 0.020048820074220722\n","EPOCH: 735, Train Loss: 0.707, Valid Loss: 0.688, Validation F1: 0.460, Learning Rate: 0.019909248842397587\n","EPOCH: 736, Train Loss: 0.692, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.019770044256881267\n","EPOCH: 737, Train Loss: 0.679, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.019631208013835683\n","EPOCH: 738, Train Loss: 0.667, Valid Loss: 0.666, Validation F1: 0.460, Learning Rate: 0.019492741804936625\n","EPOCH: 739, Train Loss: 0.673, Valid Loss: 0.684, Validation F1: 0.311, Learning Rate: 0.019354647317351193\n","EPOCH: 740, Train Loss: 0.696, Valid Loss: 0.664, Validation F1: 0.460, Learning Rate: 0.019216926233717093\n","EPOCH: 741, Train Loss: 0.706, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.019079580232122306\n","EPOCH: 742, Train Loss: 0.673, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.01894261098608449\n","EPOCH: 743, Train Loss: 0.681, Valid Loss: 0.770, Validation F1: 0.311, Learning Rate: 0.018806020164530708\n","EPOCH: 744, Train Loss: 0.664, Valid Loss: 0.671, Validation F1: 0.311, Learning Rate: 0.018669809431776995\n","EPOCH: 745, Train Loss: 0.686, Valid Loss: 0.680, Validation F1: 0.311, Learning Rate: 0.018533980447508144\n","EPOCH: 746, Train Loss: 0.682, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.018398534866757462\n","EPOCH: 747, Train Loss: 0.753, Valid Loss: 0.732, Validation F1: 0.460, Learning Rate: 0.01826347433988663\n","EPOCH: 748, Train Loss: 0.707, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.01812880051256552\n","EPOCH: 749, Train Loss: 0.675, Valid Loss: 0.675, Validation F1: 0.460, Learning Rate: 0.017994515025752222\n","EPOCH: 750, Train Loss: 0.676, Valid Loss: 0.682, Validation F1: 0.460, Learning Rate: 0.017860619515673037\n","EPOCH: 751, Train Loss: 0.680, Valid Loss: 0.703, Validation F1: 0.311, Learning Rate: 0.01772711561380247\n","EPOCH: 752, Train Loss: 0.671, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.01759400494684346\n","EPOCH: 753, Train Loss: 0.679, Valid Loss: 0.773, Validation F1: 0.311, Learning Rate: 0.017461289136707466\n","EPOCH: 754, Train Loss: 0.677, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.017328969800494733\n","EPOCH: 755, Train Loss: 0.684, Valid Loss: 0.742, Validation F1: 0.311, Learning Rate: 0.017197048550474648\n","EPOCH: 756, Train Loss: 0.678, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.017065526994065976\n","EPOCH: 757, Train Loss: 0.680, Valid Loss: 0.759, Validation F1: 0.311, Learning Rate: 0.016934406733817416\n","EPOCH: 758, Train Loss: 0.697, Valid Loss: 0.663, Validation F1: 0.460, Learning Rate: 0.01680368936738792\n","EPOCH: 759, Train Loss: 0.666, Valid Loss: 0.812, Validation F1: 0.311, Learning Rate: 0.016673376487527387\n","EPOCH: 760, Train Loss: 0.690, Valid Loss: 0.785, Validation F1: 0.311, Learning Rate: 0.016543469682057107\n","EPOCH: 761, Train Loss: 0.670, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.0164139705338505\n","EPOCH: 762, Train Loss: 0.667, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.016284880620813846\n","EPOCH: 763, Train Loss: 0.693, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.01615620151586697\n","EPOCH: 764, Train Loss: 0.658, Valid Loss: 0.673, Validation F1: 0.460, Learning Rate: 0.016027934786924186\n","EPOCH: 765, Train Loss: 0.708, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.015900081996875082\n","EPOCH: 766, Train Loss: 0.694, Valid Loss: 0.669, Validation F1: 0.460, Learning Rate: 0.015772644703565566\n","EPOCH: 767, Train Loss: 0.661, Valid Loss: 0.695, Validation F1: 0.311, Learning Rate: 0.015645624459778858\n","EPOCH: 768, Train Loss: 0.667, Valid Loss: 0.681, Validation F1: 0.460, Learning Rate: 0.01551902281321651\n","EPOCH: 769, Train Loss: 0.706, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.015392841306479665\n","EPOCH: 770, Train Loss: 0.652, Valid Loss: 0.787, Validation F1: 0.311, Learning Rate: 0.015267081477050132\n","EPOCH: 771, Train Loss: 0.749, Valid Loss: 0.668, Validation F1: 0.460, Learning Rate: 0.015141744857271778\n","EPOCH: 772, Train Loss: 0.684, Valid Loss: 0.695, Validation F1: 0.311, Learning Rate: 0.015016832974331724\n","EPOCH: 773, Train Loss: 0.664, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.01489234735024188\n","EPOCH: 774, Train Loss: 0.686, Valid Loss: 0.663, Validation F1: 0.311, Learning Rate: 0.014768289501820265\n","EPOCH: 775, Train Loss: 0.768, Valid Loss: 0.756, Validation F1: 0.460, Learning Rate: 0.014644660940672627\n","EPOCH: 776, Train Loss: 0.790, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.014521463173173967\n","EPOCH: 777, Train Loss: 0.671, Valid Loss: 0.670, Validation F1: 0.311, Learning Rate: 0.01439869770045018\n","EPOCH: 778, Train Loss: 0.667, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.014276366018359844\n","EPOCH: 779, Train Loss: 0.692, Valid Loss: 0.811, Validation F1: 0.311, Learning Rate: 0.014154469617475863\n","EPOCH: 780, Train Loss: 0.706, Valid Loss: 0.680, Validation F1: 0.311, Learning Rate: 0.014033009983067453\n","EPOCH: 781, Train Loss: 0.686, Valid Loss: 0.848, Validation F1: 0.311, Learning Rate: 0.013911988595081894\n","EPOCH: 782, Train Loss: 0.693, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.013791406928126632\n","EPOCH: 783, Train Loss: 0.763, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.013671266451451204\n","EPOCH: 784, Train Loss: 0.669, Valid Loss: 0.665, Validation F1: 0.460, Learning Rate: 0.013551568628929435\n","EPOCH: 785, Train Loss: 0.682, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.013432314919041477\n","EPOCH: 786, Train Loss: 0.687, Valid Loss: 0.717, Validation F1: 0.460, Learning Rate: 0.013313506774856172\n","EPOCH: 787, Train Loss: 0.705, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.013195145644013286\n","EPOCH: 788, Train Loss: 0.666, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.013077232968705799\n","EPOCH: 789, Train Loss: 0.682, Valid Loss: 0.677, Validation F1: 0.311, Learning Rate: 0.012959770185662495\n","EPOCH: 790, Train Loss: 0.683, Valid Loss: 0.663, Validation F1: 0.311, Learning Rate: 0.012842758726130277\n","EPOCH: 791, Train Loss: 0.665, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.012726200015856887\n","EPOCH: 792, Train Loss: 0.679, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.012610095475073408\n","EPOCH: 793, Train Loss: 0.670, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.012494446518477021\n","EPOCH: 794, Train Loss: 0.747, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.012379254555213787\n","EPOCH: 795, Train Loss: 0.669, Valid Loss: 0.666, Validation F1: 0.460, Learning Rate: 0.012264520988861395\n","EPOCH: 796, Train Loss: 0.709, Valid Loss: 0.671, Validation F1: 0.460, Learning Rate: 0.012150247217412181\n","EPOCH: 797, Train Loss: 0.739, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.012036434633255955\n","EPOCH: 798, Train Loss: 0.676, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.011923084623163167\n","EPOCH: 799, Train Loss: 0.692, Valid Loss: 0.679, Validation F1: 0.460, Learning Rate: 0.011810198568267899\n","EPOCH: 800, Train Loss: 0.692, Valid Loss: 0.666, Validation F1: 0.460, Learning Rate: 0.0116977778440511\n","EPOCH: 801, Train Loss: 0.676, Valid Loss: 0.658, Validation F1: 0.311, Learning Rate: 0.011585823820323839\n","EPOCH: 802, Train Loss: 0.661, Valid Loss: 0.656, Validation F1: 0.460, Learning Rate: 0.011474337861210538\n","EPOCH: 803, Train Loss: 0.680, Valid Loss: 0.680, Validation F1: 0.311, Learning Rate: 0.011363321325132443\n","EPOCH: 804, Train Loss: 0.658, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.011252775564791024\n","EPOCH: 805, Train Loss: 0.671, Valid Loss: 0.663, Validation F1: 0.311, Learning Rate: 0.01114270192715145\n","EPOCH: 806, Train Loss: 0.674, Valid Loss: 0.667, Validation F1: 0.460, Learning Rate: 0.011033101753426278\n","EPOCH: 807, Train Loss: 0.702, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.010923976379059059\n","EPOCH: 808, Train Loss: 0.666, Valid Loss: 0.699, Validation F1: 0.311, Learning Rate: 0.010815327133708015\n","EPOCH: 809, Train Loss: 0.678, Valid Loss: 0.656, Validation F1: 0.460, Learning Rate: 0.010707155341229896\n","EPOCH: 810, Train Loss: 0.676, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.0105994623196639\n","EPOCH: 811, Train Loss: 0.677, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.010492249381215474\n","EPOCH: 812, Train Loss: 0.675, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.010385517832240466\n","EPOCH: 813, Train Loss: 0.688, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.010279268973229089\n","EPOCH: 814, Train Loss: 0.668, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.010173504098790188\n","EPOCH: 815, Train Loss: 0.677, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.010068224497635364\n","EPOCH: 816, Train Loss: 0.660, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.009963431452563327\n","EPOCH: 817, Train Loss: 0.672, Valid Loss: 0.657, Validation F1: 0.311, Learning Rate: 0.009859126240444284\n","EPOCH: 818, Train Loss: 0.661, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.009755310132204292\n","EPOCH: 819, Train Loss: 0.679, Valid Loss: 0.679, Validation F1: 0.460, Learning Rate: 0.00965198439280991\n","EPOCH: 820, Train Loss: 0.689, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.009549150281252628\n","EPOCH: 821, Train Loss: 0.664, Valid Loss: 0.669, Validation F1: 0.311, Learning Rate: 0.009446809050533673\n","EPOCH: 822, Train Loss: 0.661, Valid Loss: 0.675, Validation F1: 0.311, Learning Rate: 0.009344961947648616\n","EPOCH: 823, Train Loss: 0.663, Valid Loss: 0.642, Validation F1: 0.460, Learning Rate: 0.009243610213572284\n","EPOCH: 824, Train Loss: 0.750, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.009142755083243576\n","EPOCH: 825, Train Loss: 0.673, Valid Loss: 0.659, Validation F1: 0.311, Learning Rate: 0.009042397785550405\n","EPOCH: 826, Train Loss: 0.672, Valid Loss: 0.687, Validation F1: 0.311, Learning Rate: 0.008942539543314799\n","EPOCH: 827, Train Loss: 0.664, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.008843181573277898\n","EPOCH: 828, Train Loss: 0.673, Valid Loss: 0.684, Validation F1: 0.311, Learning Rate: 0.008744325086085242\n","EPOCH: 829, Train Loss: 0.664, Valid Loss: 0.685, Validation F1: 0.311, Learning Rate: 0.008645971286271903\n","EPOCH: 830, Train Loss: 0.672, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.008548121372247914\n","EPOCH: 831, Train Loss: 0.670, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.008450776536283594\n","EPOCH: 832, Train Loss: 0.668, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.00835393796449503\n","EPOCH: 833, Train Loss: 0.644, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.00825760683682968\n","EPOCH: 834, Train Loss: 0.687, Valid Loss: 0.674, Validation F1: 0.311, Learning Rate: 0.008161784327051919\n","EPOCH: 835, Train Loss: 0.682, Valid Loss: 0.652, Validation F1: 0.311, Learning Rate: 0.008066471602728803\n","EPOCH: 836, Train Loss: 0.662, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.007971669825215789\n","EPOCH: 837, Train Loss: 0.669, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.007877380149642626\n","EPOCH: 838, Train Loss: 0.661, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.007783603724899258\n","EPOCH: 839, Train Loss: 0.671, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.007690341693621806\n","EPOCH: 840, Train Loss: 0.671, Valid Loss: 0.652, Validation F1: 0.311, Learning Rate: 0.007597595192178702\n","EPOCH: 841, Train Loss: 0.692, Valid Loss: 0.643, Validation F1: 0.460, Learning Rate: 0.0075053653506568065\n","EPOCH: 842, Train Loss: 0.760, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.007413653292847617\n","EPOCH: 843, Train Loss: 0.670, Valid Loss: 0.678, Validation F1: 0.311, Learning Rate: 0.007322460136233622\n","EPOCH: 844, Train Loss: 0.666, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.00723178699197467\n","EPOCH: 845, Train Loss: 0.660, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.007141634964894389\n","EPOCH: 846, Train Loss: 0.669, Valid Loss: 0.673, Validation F1: 0.311, Learning Rate: 0.007052005153466778\n","EPOCH: 847, Train Loss: 0.693, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.006962898649802824\n","EPOCH: 848, Train Loss: 0.641, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.006874316539637127\n","EPOCH: 849, Train Loss: 0.742, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.0067862599023147735\n","EPOCH: 850, Train Loss: 0.740, Valid Loss: 0.668, Validation F1: 0.311, Learning Rate: 0.00669872981077807\n","EPOCH: 851, Train Loss: 0.668, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.006611727331553585\n","EPOCH: 852, Train Loss: 0.726, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.00652525352473905\n","EPOCH: 853, Train Loss: 0.668, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.0064393094439905325\n","EPOCH: 854, Train Loss: 0.669, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.00635389613650953\n","EPOCH: 855, Train Loss: 0.666, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.006269014643030219\n","EPOCH: 856, Train Loss: 0.659, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.006184665997806833\n","EPOCH: 857, Train Loss: 0.733, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.006100851228600979\n","EPOCH: 858, Train Loss: 0.653, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.006017571356669188\n","EPOCH: 859, Train Loss: 0.725, Valid Loss: 0.658, Validation F1: 0.311, Learning Rate: 0.0059348273967503975\n","EPOCH: 860, Train Loss: 0.669, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.005852620357053657\n","EPOCH: 861, Train Loss: 0.684, Valid Loss: 0.655, Validation F1: 0.460, Learning Rate: 0.005770951239245809\n","EPOCH: 862, Train Loss: 0.667, Valid Loss: 0.654, Validation F1: 0.460, Learning Rate: 0.005689821038439269\n","EPOCH: 863, Train Loss: 0.690, Valid Loss: 0.680, Validation F1: 0.311, Learning Rate: 0.0056092307431799444\n","EPOCH: 864, Train Loss: 0.685, Valid Loss: 0.657, Validation F1: 0.311, Learning Rate: 0.005529181335435124\n","EPOCH: 865, Train Loss: 0.669, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.005449673790581616\n","EPOCH: 866, Train Loss: 0.693, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.005370709077393726\n","EPOCH: 867, Train Loss: 0.662, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.0052922881580316\n","EPOCH: 868, Train Loss: 0.673, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.005214411988029361\n","EPOCH: 869, Train Loss: 0.673, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.005137081516283587\n","EPOCH: 870, Train Loss: 0.676, Valid Loss: 0.658, Validation F1: 0.311, Learning Rate: 0.00506029768504166\n","EPOCH: 871, Train Loss: 0.665, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.004984061429890336\n","EPOCH: 872, Train Loss: 0.663, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.004908373679744321\n","EPOCH: 873, Train Loss: 0.663, Valid Loss: 0.657, Validation F1: 0.311, Learning Rate: 0.0048332353568349695\n","EPOCH: 874, Train Loss: 0.671, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.004758647376699038\n","EPOCH: 875, Train Loss: 0.682, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.004684610648167509\n","EPOCH: 876, Train Loss: 0.670, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.004611126073354577\n","EPOCH: 877, Train Loss: 0.673, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.004538194547646579\n","EPOCH: 878, Train Loss: 0.659, Valid Loss: 0.662, Validation F1: 0.311, Learning Rate: 0.004465816959691155\n","EPOCH: 879, Train Loss: 0.668, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.004393994191386358\n","EPOCH: 880, Train Loss: 0.670, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.004322727117869957\n","EPOCH: 881, Train Loss: 0.664, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.004252016607508763\n","EPOCH: 882, Train Loss: 0.666, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.004181863521888019\n","EPOCH: 883, Train Loss: 0.662, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0041122687158009485\n","EPOCH: 884, Train Loss: 0.661, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.0040432330372382865\n","EPOCH: 885, Train Loss: 0.664, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.003974757327377987\n","EPOCH: 886, Train Loss: 0.678, Valid Loss: 0.664, Validation F1: 0.311, Learning Rate: 0.00390684242057498\n","EPOCH: 887, Train Loss: 0.663, Valid Loss: 0.677, Validation F1: 0.311, Learning Rate: 0.0038394891443509606\n","EPOCH: 888, Train Loss: 0.677, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.003772698319384349\n","EPOCH: 889, Train Loss: 0.738, Valid Loss: 0.644, Validation F1: 0.460, Learning Rate: 0.0037064707595002634\n","EPOCH: 890, Train Loss: 0.681, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.00364080727166064\n","EPOCH: 891, Train Loss: 0.675, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.003575708655954324\n","EPOCH: 892, Train Loss: 0.746, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.0035111757055874384\n","EPOCH: 893, Train Loss: 0.739, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.0034472092068735974\n","EPOCH: 894, Train Loss: 0.668, Valid Loss: 0.653, Validation F1: 0.311, Learning Rate: 0.0033838099392243973\n","EPOCH: 895, Train Loss: 0.663, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0033209786751399184\n","EPOCH: 896, Train Loss: 0.678, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.0032587161801992783\n","EPOCH: 897, Train Loss: 0.662, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.0031970232130513368\n","EPOCH: 898, Train Loss: 0.673, Valid Loss: 0.659, Validation F1: 0.311, Learning Rate: 0.0031359005254054276\n","EPOCH: 899, Train Loss: 0.676, Valid Loss: 0.665, Validation F1: 0.311, Learning Rate: 0.003075348862022204\n","EPOCH: 900, Train Loss: 0.661, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.0030153689607045845\n","EPOCH: 901, Train Loss: 0.663, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0029559615522887217\n","EPOCH: 902, Train Loss: 0.690, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0028971273606351656\n","EPOCH: 903, Train Loss: 0.661, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0028388671026199465\n","EPOCH: 904, Train Loss: 0.661, Valid Loss: 0.659, Validation F1: 0.311, Learning Rate: 0.002781181488125945\n","EPOCH: 905, Train Loss: 0.678, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.002724071220034152\n","EPOCH: 906, Train Loss: 0.661, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0026675369942151805\n","EPOCH: 907, Train Loss: 0.668, Valid Loss: 0.653, Validation F1: 0.311, Learning Rate: 0.0026115794995207166\n","EPOCH: 908, Train Loss: 0.662, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.002556199417775168\n","EPOCH: 909, Train Loss: 0.679, Valid Loss: 0.666, Validation F1: 0.311, Learning Rate: 0.002501397423767371\n","EPOCH: 910, Train Loss: 0.676, Valid Loss: 0.670, Validation F1: 0.311, Learning Rate: 0.002447174185242318\n","EPOCH: 911, Train Loss: 0.665, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.002393530362893065\n","EPOCH: 912, Train Loss: 0.662, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0023404666103526484\n","EPOCH: 913, Train Loss: 0.659, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.0022879835741861534\n","EPOCH: 914, Train Loss: 0.659, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.0022360818938828133\n","EPOCH: 915, Train Loss: 0.670, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.002184762201848223\n","EPOCH: 916, Train Loss: 0.664, Valid Loss: 0.656, Validation F1: 0.311, Learning Rate: 0.0021340251233966322\n","EPOCH: 917, Train Loss: 0.673, Valid Loss: 0.652, Validation F1: 0.311, Learning Rate: 0.002083871276743332\n","EPOCH: 918, Train Loss: 0.675, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.002034301272997119\n","EPOCH: 919, Train Loss: 0.730, Valid Loss: 0.645, Validation F1: 0.460, Learning Rate: 0.001985315716152836\n","EPOCH: 920, Train Loss: 0.658, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.0019369152030840554\n","EPOCH: 921, Train Loss: 0.663, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0018891003235357252\n","EPOCH: 922, Train Loss: 0.665, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0018418716601170837\n","EPOCH: 923, Train Loss: 0.677, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.0017952297882944891\n","EPOCH: 924, Train Loss: 0.661, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0017491752763844238\n","EPOCH: 925, Train Loss: 0.662, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0017037086855465789\n","EPOCH: 926, Train Loss: 0.661, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0016588305697770257\n","EPOCH: 927, Train Loss: 0.657, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0016145414759014321\n","EPOCH: 928, Train Loss: 0.658, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.001570841943568435\n","EPOCH: 929, Train Loss: 0.656, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.0015277325052430514\n","EPOCH: 930, Train Loss: 0.671, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0014852136862001709\n","EPOCH: 931, Train Loss: 0.675, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0014432860045181907\n","EPOCH: 932, Train Loss: 0.656, Valid Loss: 0.653, Validation F1: 0.311, Learning Rate: 0.0014019499710726858\n","EPOCH: 933, Train Loss: 0.733, Valid Loss: 0.659, Validation F1: 0.311, Learning Rate: 0.0013612060895301704\n","EPOCH: 934, Train Loss: 0.675, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.00132105485634198\n","EPOCH: 935, Train Loss: 0.663, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.0012814967607382322\n","EPOCH: 936, Train Loss: 0.658, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0012425322847218314\n","EPOCH: 937, Train Loss: 0.731, Valid Loss: 0.647, Validation F1: 0.460, Learning Rate: 0.0012041619030626228\n","EPOCH: 938, Train Loss: 0.727, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.001166386083291593\n","EPOCH: 939, Train Loss: 0.677, Valid Loss: 0.646, Validation F1: 0.460, Learning Rate: 0.0011292052856952063\n","EPOCH: 940, Train Loss: 0.664, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0010926199633097156\n","EPOCH: 941, Train Loss: 0.661, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.0010566305619157446\n","EPOCH: 942, Train Loss: 0.660, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.0010212375200327917\n","EPOCH: 943, Train Loss: 0.674, Valid Loss: 0.660, Validation F1: 0.311, Learning Rate: 0.0009864412689139068\n","EPOCH: 944, Train Loss: 0.675, Valid Loss: 0.658, Validation F1: 0.311, Learning Rate: 0.0009522422325404179\n","EPOCH: 945, Train Loss: 0.661, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0009186408276168012\n","EPOCH: 946, Train Loss: 0.657, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0008856374635655695\n","EPOCH: 947, Train Loss: 0.675, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0008532325425222864\n","EPOCH: 948, Train Loss: 0.713, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0008214264593307042\n","EPOCH: 949, Train Loss: 0.661, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0007902196015379004\n","EPOCH: 950, Train Loss: 0.670, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0007596123493895991\n","EPOCH: 951, Train Loss: 0.730, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.0007296050758254958\n","EPOCH: 952, Train Loss: 0.654, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0007001981464747564\n","EPOCH: 953, Train Loss: 0.659, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.0006713919196515317\n","EPOCH: 954, Train Loss: 0.726, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0006431867463506047\n","EPOCH: 955, Train Loss: 0.671, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0006155829702431171\n","EPOCH: 956, Train Loss: 0.662, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0005885809276723664\n","EPOCH: 957, Train Loss: 0.792, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0005621809476497097\n","EPOCH: 958, Train Loss: 0.660, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.000536383351850589\n","EPOCH: 959, Train Loss: 0.674, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.0005111884546105561\n","EPOCH: 960, Train Loss: 0.648, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0004865965629214875\n","EPOCH: 961, Train Loss: 0.674, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.0004626079764278257\n","EPOCH: 962, Train Loss: 0.661, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.00043922298742292144\n","EPOCH: 963, Train Loss: 0.673, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0004164418808454862\n","EPOCH: 964, Train Loss: 0.668, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.0003942649342761173\n","EPOCH: 965, Train Loss: 0.659, Valid Loss: 0.648, Validation F1: 0.460, Learning Rate: 0.00037269241793390644\n","EPOCH: 966, Train Loss: 0.665, Valid Loss: 0.649, Validation F1: 0.460, Learning Rate: 0.00035172459467315846\n","EPOCH: 967, Train Loss: 0.662, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.0003313617199801888\n","EPOCH: 968, Train Loss: 0.661, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.00031160404197019267\n","EPOCH: 969, Train Loss: 0.728, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.00029245180138424146\n","EPOCH: 970, Train Loss: 0.661, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.00027390523158634105\n","EPOCH: 971, Train Loss: 0.662, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0002559645585605952\n","EPOCH: 972, Train Loss: 0.660, Valid Loss: 0.655, Validation F1: 0.311, Learning Rate: 0.00023863000090844634\n","EPOCH: 973, Train Loss: 0.659, Valid Loss: 0.654, Validation F1: 0.311, Learning Rate: 0.0002219017698460113\n","EPOCH: 974, Train Loss: 0.658, Valid Loss: 0.653, Validation F1: 0.460, Learning Rate: 0.00020578006920148886\n","EPOCH: 975, Train Loss: 0.727, Valid Loss: 0.652, Validation F1: 0.460, Learning Rate: 0.0001902650954127283\n","EPOCH: 976, Train Loss: 0.738, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.00017535703752478705\n","EPOCH: 977, Train Loss: 0.673, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 0.00016105607718764904\n","EPOCH: 978, Train Loss: 0.655, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.00014736238865398766\n","EPOCH: 979, Train Loss: 0.660, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.00013427613877710077\n","EPOCH: 980, Train Loss: 0.740, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.00012179748700879012\n","EPOCH: 981, Train Loss: 0.653, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 0.00010992658539750179\n","EPOCH: 982, Train Loss: 0.667, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 9.866357858642206e-05\n","EPOCH: 983, Train Loss: 0.656, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 8.800860381173449e-05\n","EPOCH: 984, Train Loss: 0.729, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 7.796179090094335e-05\n","EPOCH: 985, Train Loss: 0.660, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 6.852326227130279e-05\n","EPOCH: 986, Train Loss: 0.657, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 5.969313292829015e-05\n","EPOCH: 987, Train Loss: 0.724, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 5.1471510464262686e-05\n","EPOCH: 988, Train Loss: 0.662, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 4.385849505707529e-05\n","EPOCH: 989, Train Loss: 0.672, Valid Loss: 0.650, Validation F1: 0.460, Learning Rate: 3.685417946893144e-05\n","EPOCH: 990, Train Loss: 0.657, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 3.0458649045206346e-05\n","EPOCH: 991, Train Loss: 0.659, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 2.467198171341445e-05\n","EPOCH: 992, Train Loss: 0.661, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 1.9494247982271287e-05\n","EPOCH: 993, Train Loss: 0.663, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 1.4925510940838606e-05\n","EPOCH: 994, Train Loss: 0.673, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 1.096582625771947e-05\n","EPOCH: 995, Train Loss: 0.660, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 7.61524218043097e-06\n","EPOCH: 996, Train Loss: 0.659, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 4.873799534776957e-06\n","EPOCH: 997, Train Loss: 0.674, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 2.7415317243872916e-06\n","EPOCH: 998, Train Loss: 0.660, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 1.2184647302571073e-06\n","EPOCH: 999, Train Loss: 0.705, Valid Loss: 0.651, Validation F1: 0.460, Learning Rate: 3.046171104803541e-07\n"]}]},{"cell_type":"markdown","source":["# testデータで性能検証"],"metadata":{"id":"1WOY0uOO5jx-"}},{"cell_type":"code","source":["net.eval()\n","\n","t_true = []\n","t_pred = []\n","for label, line, len_seq in test_dataloader:\n","\n","    # t = label.to(device) # テンソルをGPUに移動\n","    x = line.to(device)\n","    len_seq.to(device)\n","\n","    h = net(x, torch.max(len_seq), len_seq)\n","    y = torch.sigmoid(h).squeeze()\n","\n","    # 予測値を格納\n","    t_pred.extend(y.detach().cpu().numpy())\n","\n","    # labelを格納\n","    t_true.extend(label.numpy())\n","\n","\n","\n","# numpy arraysに変換\n","t_pred = np.array(t_pred)\n","t_true = np.array(t_true)\n","\n","\n","# 予測の出力がロジットなので、確率に変換するためにシグモイド関数を適用\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","t_pred_sigmoid = sigmoid(t_pred)"],"metadata":{"id":"wJBajfwA5KEe","executionInfo":{"status":"ok","timestamp":1690845265037,"user_tz":420,"elapsed":29,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### ROCカーブ"],"metadata":{"id":"j6ZJX9279jke"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","\n","roc_auc = roc_auc_score(t_true, t_pred_sigmoid)\n","print(f\"ROC AUC: {roc_auc}\")\n","\n","# ROCカーブの値を計算\n","fpr, tpr, thresholds = roc_curve(t_true, t_pred_sigmoid)\n","\n","# ROCカーブをプロット\n","plt.figure(figsize=(4, 3))\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('FPR (1 - Specificity)')\n","plt.ylabel('TPR (Recall)')\n","plt.title('ROC curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"5ZGSSVgc9bRU","executionInfo":{"status":"ok","timestamp":1690845265038,"user_tz":420,"elapsed":29,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"3a77f276-a0a1-406a-fc9b-6254b74d08b6"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["ROC AUC: 0.5384615384615385\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 400x300 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### 閾値を変更した場合の各指標の値"],"metadata":{"id":"iwCrUeTs9lcI"}},{"cell_type":"code","source":["import warnings\n","from sklearn.exceptions import UndefinedMetricWarning\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","\n","# 様々な閾値で値を計算\n","thresholds = np.linspace(0, 1, 100)\n","accuracies = []\n","precisions = []\n","recalls = []\n","f1_scores = []\n","for threshold in thresholds:\n","    t_pred_class = (t_pred_sigmoid > threshold).astype(int)\n","    accuracies.append(accuracy_score(t_true, t_pred_class))\n","    precisions.append(precision_score(t_true, t_pred_class))\n","    recalls.append(recall_score(t_true, t_pred_class))\n","    f1_scores.append(f1_score(t_true, t_pred_class))\n","\n","# 各指標をプロット\n","plt.figure(figsize=(10, 6))\n","plt.plot(thresholds, accuracies, label='Accuracy')\n","plt.plot(thresholds, precisions, label='Precision')\n","plt.plot(thresholds, recalls, label='Recall')\n","plt.plot(thresholds, f1_scores, label='F1 Score')\n","plt.xlabel('Threshold')\n","plt.ylabel('Score')\n","plt.title('Each score per threshold')\n","plt.legend()\n","plt.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"aJSOvK4dvxYe","executionInfo":{"status":"ok","timestamp":1690845265854,"user_tz":420,"elapsed":821,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"f88294f0-dc39-4877-d6d1-c329a0539da2"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### 混同行列"],"metadata":{"id":"pAxORy-N9qJq"}},{"cell_type":"code","source":["# 指定した閾値で混同行列を計算\n","threshold = 0.619589535\n","t_pred_class = (t_pred_sigmoid > threshold).astype(int)\n","cm = confusion_matrix(t_true, t_pred_class)\n","print(f\"混同行列の閾値 {threshold}:\\n{cm}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXfp7fSU9NqO","executionInfo":{"status":"ok","timestamp":1690845265854,"user_tz":420,"elapsed":6,"user":{"displayName":"Sachiko U","userId":"14709320199268636000"}},"outputId":"5484b1ef-bd7d-42f1-cec8-45630e3bf852"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["混同行列の閾値 0.619589535:\n","[[25  1]\n"," [25  1]]\n"]}]}]}